[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Multivariate Data Analysis",
    "section": "",
    "text": "Preface\nThis book contains the course notes for STAT 4750/5750 (Introduction to Multivariate Data Analysis) at Iowa State University. This course is designed for undergraduate students in statistics and data science and graduate students from the applied sciences with majors outside statistics. The prerequisite for this course includes STAT 3010 or STAT 3260 (for undergraduates) or STAT 5101 for graduate students. Knowledge of matrix algebra is recommended but not required to understand the topics covered in this book.\nThe course STAT 3010 (Intermediate Statistical Concepts and Methods) covers statistical concepts and methods used in the analysis of observational data. Topics include analysis of single sample, two sample and paired sample data; simple and multiple linear regression; model building and analysis of residuals; one-way ANOVA, tests of independence for contingency tables, and logistic regression.\nThe course STAT 3260 (Introduction to Business Statistics II) covers multiple regression, regression diagnostics, model building, applications in analysis of variance and time series, random variables, conditional probability, and data visualization.\nThe course STAT 5101 (Statistical Methods for Research Workers) was renamed from the previous course STAT 5870 starting Fall 2025. STAT 5101 is a first course in statistics for graduate students from the applied sciences, and covers topics including basic experimental designs and analysis of variance, analysis of categorical data, logistic and log-linear regression, likelihood-based inference, and the use of simulation.\nStudents who have the needed backgrounds shall find the statistical concepts and methods in this book easy to follow and understand. All the methods are illustrated with various examples with step-by-step solutions and extensive R code. Exercises are also given at each chapter to help students better understand the statistical methods and apply these methods for real data analysis by adapting the corresponding R code in the book.\nThe materials in this book are largely influenced by previous course notes taught by several instructors including Yumou Qiu and Kenneth Koehler in the Department of Statistics at Iowa State University.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#course-outline",
    "href": "ch1/01-intro.html#course-outline",
    "title": "1  Introduction to Multivariate Data",
    "section": "",
    "text": "Introduction to Multivariate Data\nNumerical Summaries and Visualization of Multivariate Data\nMultivariate Normal Distribution\nComparing Centers of Distributions\n(Hotelling T^2, MANOVA, Repeated Measures)\nPrincipal Component Analysis\n(Summarizing data in lower dimensions)\nExploratory Factor Analysis\n(What to do when the variables of interest cannot be directly observed.)\nMulti-Dimensional Scaling\nCluster Analysis\nDiscriminant Analysis and Classification\n(Including linear discriminants, logistic regression, classification trees, and random forests)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#objectives-of-multivariate-analysis",
    "href": "ch1/01-intro.html#objectives-of-multivariate-analysis",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.2 Objectives of Multivariate Analysis",
    "text": "1.2 Objectives of Multivariate Analysis\n\nUnderstand dependencies among variables: What is the nature of associations among variables?\nPrediction: If variables are associated, then we might be able to predict the value of some of them given information on the others. (Statistical inference)\nHypothesis testing: Are differences in sets of response means for two or more groups large enough to be distinguished from sampling variation? (Statistical inference)\nDimensionality reduction: Can we reduce the dimensionality of the problem by considering a small number of (linear) combinations of a large number of measurements without losing important information?\n\nPrincipal Components\nFactor Analysis\nMultidimensional Scaling\n\nGrouping (Cluster Analysis): Identify groups of “similar” units using a common set of measured traits.\nClassification: Classify units into previously defined groups using a common set of measured traits.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#introduction-to-r-and-rstudio",
    "href": "ch1/01-intro.html#introduction-to-r-and-rstudio",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.3 Introduction to R and RStudio",
    "text": "1.3 Introduction to R and RStudio\n\n1.3.1 Getting Started\nTo download R, please choose your preferred CRAN mirror. Here I recommend the mirror 0-Cloud available at https://cloud.r-project.org/.\nInstall R on macOS\nFor macOS users, below are the steps you need to install R.\n\nInstall Xcode (e.g., via the App Store). Skip this step if your Mac already has Xcode installed.\nInstall XQuartz.\nGo to https://cloud.r-project.org/ and click “Download R for macOS.”\nClick on the download link for the latest R version for macOS and follow the instruction.\n\nInstall R on Windows:\nFor Windows users, the following instructions guide you to install R.\n\nGo to https://cloud.r-project.org/ and click “Download R for Windows.”\nClick “install R for the first time.”\nChoose a download mirror (any CRAN mirror will work).\nClick on the download link for the latest R version for Windows and follow the instruction\n\nInstall RStudio\nRStudio has multiple panes in the window, open by default: one for writing and editing code, another for executing it, another for plots produced or help, and another that lists the R data objects available. RStudio can be download for free at https://posit.co/download/rstudio-desktop/.\n\n\n1.3.2 Introduction to R Programming\n\n\n\n\n\n\nSome Tips: R Working Environment\n\n\n\n\n\nWhenever you work with R for data analysis, it is recommended to load all the packages used in the data analysis pipeline before the function sessionInfo(). In addition, if random numbers are generated, it is also recommended to set random seed to ensure reproducibility using set.seed().\n\n\nR Working Environment\n# load packages \nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(lubridate)\n\nsessionInfo()\n\n\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.3.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lubridate_1.9.4 readr_2.1.5     tidyr_1.3.1     dplyr_1.1.4    \n[5] ggplot2_3.5.2  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5        cli_3.6.5          knitr_1.50         rlang_1.1.6       \n [5] xfun_0.52          purrr_1.0.4        generics_0.1.4     jsonlite_2.0.0    \n [9] glue_1.8.0         htmltools_0.5.8.1  hms_1.1.3          scales_1.4.0      \n[13] rmarkdown_2.29     grid_4.4.3         evaluate_1.0.3     tibble_3.2.1      \n[17] tzdb_0.5.0         fastmap_1.2.0      yaml_2.3.10        lifecycle_1.0.4   \n[21] compiler_4.4.3     RColorBrewer_1.1-3 timechange_0.3.0   htmlwidgets_1.6.4 \n[25] pkgconfig_2.0.3    rstudioapi_0.17.1  farver_2.1.2       digest_0.6.37     \n[29] R6_2.6.1           tidyselect_1.2.1   pillar_1.10.2      magrittr_2.0.3    \n[33] withr_3.0.2        tools_4.4.3        gtable_0.3.6      \n\n\n\n\n\n\n\n\n\n\n\nR is a Calculator\n\n\n\n\n\n\nCode\n# Numeric, logical, character types\n3.14159             # numeric\n\n[1] 3.14159\n\nCode\nT                   # logical, can also be TRUE\n\n[1] TRUE\n\nCode\nF                   # logical, can also be FALSE \n\n[1] FALSE\n\nCode\n\"Stat 4750/5750\"    # character\n\n[1] “Stat 4750/5750”\n\nCode\n# Basic arithmetic operators\n1 + 2\n\n[1] 3\n\nCode\n20 - 3\n\n[1] 17\n\nCode\n2 * 6\n\n[1] 12\n\nCode\n4 / 3\n\n[1] 1.333333\n\nCode\n2 ^ 4\n\n[1] 16\n\nCode\n-3.14\n\n[1] -3.14\n\nCode\n(1 + 2) * (3 / 4)  # use parenthesis\n\n[1] 2.25\n\nCode\n2 == 1\n\n[1] FALSE\n\nCode\n# Vector\nc()  # empty vector\n\nNULL\n\nCode\nc(1, 2, 3, 4)\n\n[1] 1 2 3 4\n\nCode\n1:4\n\n[1] 1 2 3 4\n\nCode\n# Look up the function help, 3 ways:\n# Following 3 ways work for most functions\n          # 1. search in help pane\n?sum      # 2. use ?\nsum(1:4)  # 3. move your cursor to the function, then press F1, the easiest way\n\n[1] 10\n\nCode\n# The 3rd way doesn't work for functions having some symbols, like +, ==, %*%\n          # 1. search in help pane\n?`+`      # 2. use ? but wrap the symbol with ``\n\n\n\n\n\n\n\n\n\n\nR Objects\n\n\n\n\n\n\n\nCode\n# Assignment operator &lt;-\n\n# Numeric class\nmynumbers &lt;- 5:12\nmynumbers\n\n\n[1]  5  6  7  8  9 10 11 12\n\n\nCode\nmynumbers + 2\n\n\n[1]  7  8  9 10 11 12 13 14\n\n\nCode\nmynumbers * 10\n\n\n[1]  50  60  70  80  90 100 110 120\n\n\nCode\ntypeof(mynumbers)      # type of an object\n\n\n[1] \"integer\"\n\n\nCode\n# check if is numeric (both integer and double type are numeric)\nis.numeric(mynumbers)  \n\n\n[1] TRUE\n\n\nCode\nis.vector(mynumbers)   # check if is vector\n\n\n[1] TRUE\n\n\nCode\nlength(mynumbers)      # length of an object\n\n\n[1] 8\n\n\nCode\n# Character class\nmytext &lt;- c(\"hello\", \"class\", \"four\") \nmytext\n\n\n[1] \"hello\" \"class\" \"four\" \n\n\nCode\ntypeof(mytext)\n\n\n[1] \"character\"\n\n\nCode\nis.numeric(mytext)\n\n\n[1] FALSE\n\n\nCode\nis.character(mytext)\n\n\n[1] TRUE\n\n\nCode\nis.character(mynumbers)\n\n\n[1] FALSE\n\n\nCode\nis.vector(mytext)\n\n\n[1] TRUE\n\n\nCode\nlength(mytext)\n\n\n[1] 3\n\n\nCode\n# Logical class\nmylogic &lt;- c(TRUE, FALSE, TRUE, TRUE)\ntypeof(mylogic)\n\n\n[1] \"logical\"\n\n\nCode\n# Factor class\ngender &lt;- c(\"male\", \"female\", \"female\", \"female\", \"male\") \ngender\n\n\n[1] \"male\"   \"female\" \"female\" \"female\" \"male\"  \n\n\nCode\nis.vector(gender)\n\n\n[1] TRUE\n\n\nCode\nis.character(gender)\n\n\n[1] TRUE\n\n\nCode\nis.vector(gender)\n\n\n[1] TRUE\n\n\nCode\nis.factor(gender)\n\n\n[1] FALSE\n\n\nCode\ngenderf &lt;- factor(gender)\ngenderf\n\n\n[1] male   female female female male  \nLevels: female male\n\n\nCode\nis.character(genderf)\n\n\n[1] FALSE\n\n\nCode\nis.factor(genderf)\n\n\n[1] TRUE\n\n\nCode\nsummary(mynumbers)  # numeric: 5-number summary\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00    6.75    8.50    8.50   10.25   12.00 \n\n\nCode\nsummary(mylogic)    # logical: count how many T and F\n\n\n   Mode   FALSE    TRUE \nlogical       1       3 \n\n\nCode\nsummary(mytext)     # character:\n\n\n   Length     Class      Mode \n        3 character character \n\n\nCode\nsummary(genderf)    # factor: count the frequency\n\n\nfemale   male \n     3      2 \n\n\nCode\n# List class\nmylist &lt;- list(1, \"ABC\", FALSE)\nmylist\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"ABC\"\n\n[[3]]\n[1] FALSE\n\n\nCode\nis.vector(mylist)\n\n\n[1] TRUE\n\n\nCode\nis.list(mylist)\n\n\n[1] TRUE\n\n\nCode\nlength(mylist)\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\n\n\nWorking with Matrices\n\n\n\n\n\n\n\nCode\n# All elements should be the same type\nmydata &lt;- matrix(c(140, 120, 160, 145, 125, 65, 60, 63, 66, 61), ncol = 2, byrow = FALSE) \nmydata\n\n\n     [,1] [,2]\n[1,]  140   65\n[2,]  120   60\n[3,]  160   63\n[4,]  145   66\n[5,]  125   61\n\n\nCode\ndim(mydata)  # dimensions\n\n\n[1] 5 2\n\n\nCode\ncolnames(mydata) &lt;- c(\"Weight.lbs\", \"Height.in\")\nrownames(mydata) &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nmydata\n\n\n  Weight.lbs Height.in\na        140        65\nb        120        60\nc        160        63\nd        145        66\ne        125        61\n\n\nCode\nsummary(mydata)  # summary of each column\n\n\n   Weight.lbs    Height.in \n Min.   :120   Min.   :60  \n 1st Qu.:125   1st Qu.:61  \n Median :140   Median :63  \n Mean   :138   Mean   :63  \n 3rd Qu.:145   3rd Qu.:65  \n Max.   :160   Max.   :66  \n\n\n\n\n\n\n\n\n\n\n\nWorking with Data Frames\n\n\n\n\n\n\n\nData Frames\n# Different columns can have different types\ndf &lt;- data.frame(Weight.lbs = c(140, 120, 160, 145, 125, 180, 165),\n                 Height.in = c(65, 60, 63, 66, 61, 70, 68),\n                 Gender = c(rep(\"Female\", 5), rep(\"Male\", 2)), stringsAsFactors = T)\ndf\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n7        165        68   Male\n\n\nData Frames\ndim(df)\n\n\n[1] 7 3\n\n\nData Frames\nhead(df)     # the first 6 rows\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n\n\nData Frames\nsummary(df)  # summary of each column\n\n\n   Weight.lbs      Height.in        Gender \n Min.   :120.0   Min.   :60.00   Female:5  \n 1st Qu.:132.5   1st Qu.:62.00   Male  :2  \n Median :145.0   Median :65.00             \n Mean   :147.9   Mean   :64.71             \n 3rd Qu.:162.5   3rd Qu.:67.00             \n Max.   :180.0   Max.   :70.00             \n\n\nData Frames\nstr(df)      # structure of the data frame\n\n\n'data.frame':   7 obs. of  3 variables:\n $ Weight.lbs: num  140 120 160 145 125 180 165\n $ Height.in : num  65 60 63 66 61 70 68\n $ Gender    : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 2\n\n\na tibble is a modern implementation of a data frame, designed to be more user-friendly and efficient, especially when working with large datasets.\n\n\ntibble\n# install.packages(\"tibble\")\nlibrary(tibble)\n# create a tibble from an existing object\nas_tibble(df) \n\n\n# A tibble: 7 × 3\n  Weight.lbs Height.in Gender\n       &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; \n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70 Male  \n7        165        68 Male  \n\n\ntibble\n# create a new tibble \ntibble(x=1:5, \n       y=1.0,\n       z=x^2+y)\n\n\n# A tibble: 5 × 3\n      x     y     z\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     2\n2     2     1     5\n3     3     1    10\n4     4     1    17\n5     5     1    26\n\n\ntibble\n# define a row-by-row tibble\ntribble(\n  ~x, ~y, ~z,\n  \"a\", 2, 1,\n  \"b\", 3, 4\n)\n\n\n# A tibble: 2 × 3\n  x         y     z\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a         2     1\n2 b         3     4\n\n\n\n\n\n\n\n\n\n\n\nOperations on Matrix and Data Frame\n\n\n\n\n\n\n\nCode\nmydata[, 1]                     # extract the first column\n\n\n  a   b   c   d   e \n140 120 160 145 125 \n\n\nCode\nmydata[1, ]                     # extract the first row\n\n\nWeight.lbs  Height.in \n       140         65 \n\n\nCode\nmydata[1:2, ]                   # extract the first two rows\n\n\n  Weight.lbs Height.in\na        140        65\nb        120        60\n\n\nCode\nmydata[3, 2]                    # extract the element in the third row and the second column\n\n\n[1] 63\n\n\nCode\ndf[seq(1, 7, 2), ]              # extract every second row\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n3        160        63 Female\n5        125        61 Female\n7        165        68   Male\n\n\nCode\nseq(1, 7, 2)\n\n\n[1] 1 3 5 7\n\n\nCode\nsubset(df, Gender == \"Male\")    # select based on value\n\n\n  Weight.lbs Height.in Gender\n6        180        70   Male\n7        165        68   Male\n\n\nCode\nt(mydata)                       # transpose of matrix\n\n\n             a   b   c   d   e\nWeight.lbs 140 120 160 145 125\nHeight.in   65  60  63  66  61\n\n\nCode\nmydata[, 1] * mydata[, 2]       # element-wise multiplication\n\n\n    a     b     c     d     e \n 9100  7200 10080  9570  7625 \n\n\nCode\nmydata %*% t(mydata)            # matrix multiplication\n\n\n      a     b     c     d     e\na 23825 20700 26495 24590 21465\nb 20700 18000 22980 21360 18660\nc 26495 22980 29569 27358 23843\nd 24590 21360 27358 25381 22151\ne 21465 18660 23843 22151 19346\n\n\n\n\n\n\n\n\n\n\n\nPlotting with the ggplot2 Package\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\ndata(\"USArrests\")\ndat = USArrests %&gt;% as_tibble()\ndat %&gt;% \n  ggplot(aes(x=UrbanPop, y=Murder)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat_long = dat %&gt;%\n  tidyr::pivot_longer(1:4,names_to = \"Variable\", values_to = \"Value\") \nhead(dat_long)\n\n\n# A tibble: 6 × 2\n  Variable Value\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Murder    13.2\n2 Assault  236  \n3 UrbanPop  58  \n4 Rape      21.2\n5 Murder    10  \n6 Assault  263  \n\n\nCode\n# faceted histogram\nggplot(dat_long, aes(Value)) + \n  geom_histogram(bins=20, fill=\"grey80\", color=\"white\") + \n  facet_wrap(~Variable, scales=\"free\") + \n  labs(title = \"Distributions by Variable\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#organization-of-data-and-notation",
    "href": "ch1/01-intro.html#organization-of-data-and-notation",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.4 Organization of Data and Notation",
    "text": "1.4 Organization of Data and Notation\n\nn = the number of observations or units\n\np = the number of variables measured on each unit\n\nIf p = 1, then we are back in the usual univariate setting\n\nx_{ik} = the i-th observation of the k-th variable\n\n\n\\text{Observations} \\quad \\overset{\\text{Variables}}{\n\\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\n}\n\n\nData matrix:  X_{n \\times p}=\\left[ \\begin{array}{cccc} x_{11} & x_{12} & \\cdots & x_{1p} \\\\ x_{21} & x_{22} & \\cdots & x_{2p} \\\\ \\vdots & \\vdots & & \\vdots  \\\\ x_{n1} & x_{n2} & \\cdots & x_{np}\\end{array} \\right ] \nThis can be written as n rows or as p columns \nX_{n \\times p} =\n\\begin{bmatrix}\n\\mathbf{x}_1^{\\prime} \\\\\n\\mathbf{x}_2^{\\prime} \\\\\n\\vdots \\\\\n\\mathbf{x}_n^{\\prime}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{x}_1^{\\top} \\\\\n\\mathbf{x}_2^{\\top} \\\\\n\\vdots \\\\\n\\mathbf{x}_n^{\\top}\n\\end{bmatrix}\n=\n\\left[ \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_p \\right]\n where both \\prime and \\top represent matrix transpose.\n\n\n\nR Code: Data Organization\nX = as.matrix(USArrests)\ndim(X)\n\n\n[1] 50  4\n\n\n\n\nR Code: Matrix Transpose\nt(X[1:5,])\n\n\n         Alabama Alaska Arizona Arkansas California\nMurder      13.2   10.0     8.1      8.8        9.0\nAssault    236.0  263.0   294.0    190.0      276.0\nUrbanPop    58.0   48.0    80.0     50.0       91.0\nRape        21.2   44.5    31.0     19.5       40.6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#descriptive-statistics",
    "href": "ch1/01-intro.html#descriptive-statistics",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.5 Descriptive Statistics",
    "text": "1.5 Descriptive Statistics\n\n1.5.1 Sample Mean\n\nThe sample mean of the kth variable (k = 1,...,p) is \n\\bar{x}_k = \\frac{1}{n} \\sum_{i = 1}^n x_{ik}\n\n\n\n\n1.5.2 Sample Variance and Sample Standard Deviation\n\nThe sample variance of the kth variable is \ns^2_k = \\frac{1}{n-1} \\sum_{i=1}^n (x_{ik} - \\bar{x}_k)^2  \n\nThe sample standard deviation is given by \ns_k = \\sqrt{s^2_k}\n\nWe often use s_{kk} to denote the sample variance for the k-th variable. Thus, \ns^2_k = s_{kk}\n\n\n\n\n1.5.3 Sample Covariance and Sample Correlation\n\nThe sample covariance between variable k and variable j is computed as \ns_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (x_{ij} - \\bar{x}_j) (x_{ik} - \\bar{x}_k)\n\nIf variables k and j are independent, the population covariance will be exactly zero, but the sample covariance will vary about zero.\nThe sample correlation between variables k and j is defined as \nr_{jk} = \\frac{s_{jk}}{\\sqrt{s_{jj}} \\sqrt{s_{kk}}}\n\nr_{jk} is between -1 and 1.\nr_{jk} = r_{kj}\nThe sample correlation is equal to the sample covariance if measurements are standardized.\nThe sample correlation (r_{ij}) will vary about the value of the population correlation (\\rho_{ij})\n\n\n\n\n\n\n\nR Code: Descriptive Statistics\n\n\n\n\n\n\n# load built-in US crime rates data\ndata(\"USArrests\") \ndat = USArrests \nhead(dat)\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\n\n\nSample mean\nmu = colMeans(dat)\nmu \n\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\n\nSample mean\nlibrary(dplyr)\ndat %&gt;% \n  summarise(across(where(is.numeric), mean))\n\n\n  Murder Assault UrbanPop   Rape\n1  7.788  170.76    65.54 21.232\n\n\n\n\nSample variance\ns2 = apply(dat, 2, var)\ns2 \n\n\n    Murder    Assault   UrbanPop       Rape \n  18.97047 6945.16571  209.51878   87.72916 \n\n\nSample variance\n# using dplyr\ndat %&gt;% \n  summarise(across(where(is.numeric), var))\n\n\n    Murder  Assault UrbanPop     Rape\n1 18.97047 6945.166 209.5188 87.72916\n\n\n\n\nSample standard deviation\n# compute standard deviation from data \ns = apply(dat, 2, sd)  \n# or from sample variance \ns = sqrt(s2)\ns \n\n\n   Murder   Assault  UrbanPop      Rape \n 4.355510 83.337661 14.474763  9.366385 \n\n\n\n\nSample covariance\nn = nrow(dat)\ns_jk = 1/(n-1) * sum((dat[,1] - mu[1]) * (dat[,2] - mu[2]))\ns_jk \n\n\n[1] 291.0624\n\n\n\n\nSample correlation\nr_jk = s_jk / sqrt(s2[1] * s2[2])\n\n\n\n\n\n\n\n1.5.4 Covariance and Correlation Measures\n\nCovariance and correlation measure linear association.\nOther non-linear (or curved) relationships may exist among variables even if r_{jk} = 0.\nA population correlation of zero means no linear association,\nbut it does not necessarily imply independence.\n\n\n\n\n\n\nCorrelation Measures Linear Association\n\n\n\n\n\n\n\n\n\nNonlinear Dependence with (Near) Zero Correlation",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#matrix-organization-of-descriptive-statistics",
    "href": "ch1/01-intro.html#matrix-organization-of-descriptive-statistics",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.6 Matrix Organization of Descriptive Statistics",
    "text": "1.6 Matrix Organization of Descriptive Statistics\n\n1.6.1 Sample Mean\n\nSample mean: \\bar{\\mathbf{x}} is the p \\times 1 vector of sample means:\n\n\n\\bar{\\mathbf{x}} =\n\\begin{bmatrix}\n\\bar{x}_1 \\\\\n\\bar{x}_2 \\\\\n\\vdots \\\\\n\\bar{x}_p\n\\end{bmatrix}\n\n\n\\bar{\\mathbf{x}} is an estimate of the vector of population means:\n\n\n\\boldsymbol{\\mu} =\n\\begin{bmatrix}\n\\mu_1 \\\\\n\\mu_2 \\\\\n\\vdots \\\\\n\\mu_p\n\\end{bmatrix}\n\n\n\nR Code: Sample Mean\nX = as.matrix(USArrests)\nxbar = colMeans(X)\nxbar \n\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\n\n\nCentered Data: X_c = X - \\mathbf{1}_n \\bar{\\mathbf{x}}^\\top\n\n\n\nR Code: Centered Data\nn = nrow(X) \nones_n = matrix(1, n, ncol=1)\nXc = X - ones_n %*% t(xbar)\n\n\n\n\n1.6.2 Sample Covariance\n\nS is the p \\times p symmetric matrix of sample variances (on the diagonal) and sample covariances (the off-diagonal elements):\n\n\nS =\n\\begin{bmatrix}\ns_{11} & s_{12} & s_{13} & \\cdots & s_{1p} \\\\\ns_{21} & s_{22} & s_{23} & \\cdots & s_{2p} \\\\\n\\vdots & \\vdots & \\vdots &        & \\vdots \\\\\ns_{p1} & s_{p2} & s_{p3} & \\cdots & s_{pp}\n\\end{bmatrix}\n= \\frac{1}{n-1} \\sum_{i=1}^n (\\mathbf{x}_i - \\bar{\\mathbf{x}})(\\mathbf{x}_i - \\bar{\\mathbf{x}})^{\\top} = \\frac{1}{n-1} X_c^\\top X_c\n\n\nS is an estimate of the population covariance matrix:\n\n\n\\Sigma =\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\sigma_{13} & \\cdots & \\sigma_{1p} \\\\\n\\sigma_{21} & \\sigma_{22} & \\sigma_{23} & \\cdots & \\sigma_{2p} \\\\\n\\vdots      & \\vdots      & \\vdots      &        & \\vdots      \\\\\n\\sigma_{p1} & \\sigma_{p2} & \\sigma_{p3} & \\cdots & \\sigma_{pp}\n\\end{bmatrix}\n\n\n\nR Code: Sample Covariance\nS = cov(X) \n# or using matrix algebra\nS_mat = t(Xc)%*%Xc/(n-1)\nsignif(cbind(S, S_mat),4)\n\n\n          Murder Assault UrbanPop   Rape  Murder Assault UrbanPop   Rape\nMurder    18.970   291.1    4.386  22.99  18.970   291.1    4.386  22.99\nAssault  291.100  6945.0  312.300 519.30 291.100  6945.0  312.300 519.30\nUrbanPop   4.386   312.3  209.500  55.77   4.386   312.3  209.500  55.77\nRape      22.990   519.3   55.770  87.73  22.990   519.3   55.770  87.73\n\n\n\n\n1.6.3 Sample Correlation\n\nThe p \\times p matrix of sample correlations is also symmetric:\n\n\nR =\n\\begin{bmatrix}\n1       & r_{12} & r_{13} & \\cdots & r_{1p} \\\\\nr_{21}  & 1      & r_{23} & \\cdots & r_{2p} \\\\\n\\vdots  & \\vdots & \\vdots &        & \\vdots \\\\\nr_{p1}  & r_{p2} & r_{p3} & \\cdots & 1\n\\end{bmatrix}\n= D^{-1/2} \\, S \\, D^{-1/2}\n\n\nD^{-1/2} is a diagonal matrix with (j,j) entry 1/\\sqrt{s_{jj}} = 1/s_j, i.e.,\n\n\nD^{-1/2} =\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{s_{11}}} & 0                       & 0                       & \\cdots & 0 \\\\\n0                       & \\frac{1}{\\sqrt{s_{22}}} & 0                       & \\cdots & 0 \\\\\n\\vdots                  & \\vdots                  & \\vdots                  &        & \\vdots \\\\\n0                       & 0                       & 0                       & \\cdots & \\frac{1}{\\sqrt{s_{pp}}}\n\\end{bmatrix}\n\n\nR is an estimate of the population correlation matrix \nP =\n\\begin{bmatrix}\n1          & \\rho_{12} & \\rho_{13} & \\cdots & \\rho_{1p} \\\\\n\\rho_{21}  & 1         & \\rho_{23} & \\cdots & \\rho_{2p} \\\\\n\\vdots     & \\vdots    & \\vdots    &        & \\vdots   \\\\\n\\rho_{p1}  & \\rho_{p2} & \\rho_{p3} & \\cdots & 1\n\\end{bmatrix}\n\n\n\n\nR Code: Sample Correlation\nR = cor(X)\nR\n\n\n             Murder   Assault   UrbanPop      Rape\nMurder   1.00000000 0.8018733 0.06957262 0.5635788\nAssault  0.80187331 1.0000000 0.25887170 0.6652412\nUrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\nRape     0.56357883 0.6652412 0.41134124 1.0000000\n\n\n\n\nR Code: Pairwise Scatterplots and Correlations\nGGally::ggpairs(dat)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#standardization",
    "href": "ch1/01-intro.html#standardization",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.7 Standardization",
    "text": "1.7 Standardization\n\n1.7.1 Standardized Data (or z-Scores)\n\nSuppose x_{ij} is the measurement on the j-th outcome variable for the i-th subject in the data set.\nThe standardized value is\n\nz_{ij} = \\frac{x_{ij} - \\bar{x}_{j}}{s_j}\n\nThe entire set of p standardized responses for the i-th subject can be computed as\n\n\\mathbf{z}_i =\n\\begin{bmatrix}\nz_{i1} \\\\\nz_{i2} \\\\\n\\vdots \\\\\nz_{ip}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\dfrac{x_{i1} - \\bar{x}_{1}}{s_1} \\\\\n\\dfrac{x_{i2} - \\bar{x}_{2}}{s_2} \\\\\n\\vdots \\\\\n\\dfrac{x_{ip} - \\bar{x}_{p}}{s_p}\n\\end{bmatrix}\n= D^{-1/2} (\\mathbf{x}_i - \\bar{\\mathbf{x}})\n\n\n\n\nR Code: Standardized Data\ns_j = sqrt(diag(S))\n\nDsqrt = diag(1/s_j)\n\n# using matrix algebra\nZ =  (X -  matrix(1, nrow(X), 1) %*% matrix(xbar, 1)) %*% Dsqrt\n\n# using scale function \nX_scaled = as.matrix(scale(X, center=TRUE, scale=TRUE))\n\n\n# using mutate function\ndat_scaled &lt;- dat %&gt;%\n  mutate(across(everything(), ~ (.x - mean(.x)) / sd(.x)))\n\n\n\n\nR Code: Plotting the Data\np1 = ggplot(dat, aes(Murder, Assault)) + \n  geom_point(alpha=0.8) + \n  labs(title=\"Unscaled\")\n\np2 = ggplot(dat_scaled, aes(Murder, Assault)) + \n  geom_point(alpha=.8) + \n  labs(title=\"Standardized (z-scores)\")\n\npatchwork::wrap_plots(p1, p2, ncol=1)\n\n\n\n\n\n\n\n\n\n\n\n1.7.2 Standardized Population Mean\n\nThe vector of true means for a set of standardized responses is\na vector of zeros:\n\n\nE(\\mathbf{z}_i) =\nE\\begin{bmatrix}\nz_{i1} \\\\\nz_{i2} \\\\\n\\vdots \\\\\nz_{ip}\n\\end{bmatrix}\n=\nE\\begin{bmatrix}\n\\dfrac{x_{i1} - \\bar{x}_{1}}{s_1} \\\\\n\\dfrac{x_{i2} - \\bar{x}_{2}}{s_2} \\\\\n\\vdots \\\\\n\\dfrac{x_{ip} - \\bar{x}_{p}}{s_p}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{bmatrix}\n\n\nThe vector of estimated means for a set of standardized responses\nis also a vector of zeros.\n\n\n\n1.7.3 Standardized Population Covariance\n\nThe true covariance matrix for a set of standardized responses is the population correlation matrix:\n\n\n\\text{Var}(\\mathbf{z}_i) = P =\n\\begin{bmatrix}\n1 & \\rho_{12} & \\cdots & \\rho_{1p} \\\\\n\\rho_{21} & 1 & \\cdots & \\rho_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho_{p1} & \\rho_{p2} & \\cdots & 1\n\\end{bmatrix}\n\n\nAn estimate of the true covariance matrix for a set of standardized responses is the sample correlation matrix:\n\n\n\\widehat{\\text{Var}(\\mathbf{z}_i)} = R =\n\\begin{bmatrix}\n1 & r_{12} & \\cdots & r_{1p} \\\\\nr_{21} & 1 & \\cdots & r_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nr_{p1} & r_{p2} & \\cdots & 1\n\\end{bmatrix}\n= D^{-1/2} S D^{-1/2}",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html#exercises",
    "href": "ch1/01-intro.html#exercises",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\n1.8.1 Exercise 1: Data Types\nCommon types of objects for data analysis are numeric, character, logical, factors, and dates. Character data do not have numerical values, such as names of people or words in a book, Logical data takes values of true or false and can be used to make decisions.\n\nFor each of the following commands, either explain why they should be errors, or explain the non-erroneous result.\n\n    x &lt;- c(\"1\",\"2\",\"3\")\n    max(x)\n    sort(x)\n    sum(x)\n\nFor the next two commands, either explain their results, or why they should produce errors.\n\n    y &lt;- c(\"1\",3,4)\n    y[2] + y[3]\n\nFor the next two commands, either explain their results, or why they should produce errors.\n\n    z &lt;- data.frame(z1=\"1\", z2=3, z3=5)\n    z[1,2] + z[1,3]\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\nx is bound to a vector of characters instead of numerical values. The functions max, sort, sum should take numerical values as input, so the values in x are first converted from characters to numerical values implicitly and then the functions apply to these incorrect numerical values\ny is a vector of characters, which cannot be used for addition\nz is a data frame, but the variable z1 is a character while z2 and z3 are numerical. Adding z2 and z3 will produce the correct results.\n\n\n\n\n\n\n1.8.2 Exercise 2: Working with Matrix and Data Frames\n\nA matrix is a 2D array, with rows and columns, much like you would have seen in linear algebra. Primarily we think of these as numeric objects. Arrays can have more than two dimensions. In multivariate analysis we are typically thinking of data in the form of a matrix, with samples/cases in the rows and variables represented as columns. Data frames are 2D arrays that could have multiple types of data in different columns. Lists are collections of possibly different length and different types of objects.\n\n\nCreate a matrix and print it out.\n\n\n\nView Solution\ndat = matrix(c(140, 120, 160, 145, 125, \n               65, 60, 63, 66, 61), \n             ncol = 2, byrow = FALSE) \n\n\n\n\nView Solution\ndat # or print(dat) \n\n\n     [,1] [,2]\n[1,]  140   65\n[2,]  120   60\n[3,]  160   63\n[4,]  145   66\n[5,]  125   61\n\n\n\nRename the column names of a matrix.\n\n\n\nView Solution\ncolnames(dat) = c(\"weight.lbs\", \"Height.in\")\ndat \n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        120        60\n[3,]        160        63\n[4,]        145        66\n[5,]        125        61\n\n\n\nData frames can store both columns of numeric data and columns of character data, columns of integers, and factors.\n\n\nCreate a data frame with Male and Female observations, and print out the data frame.\n\n\n\nView Solution\ndf = data.frame(\n  Weight.lbs = c(140, 120, 160, 145, 125,\n       180, 165), \n  Height.in = c(65, 60, 63, 66, 61, 70, 68),\n  Gender = c(rep(\"Female\", 5), rep(\"Male\", 2))\n  ) \n\ndf\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n7        165        68   Male\n\n\n\nGet the rows and columns of a data frame.\n\n\n\nView Solution\ndim(df)\n\n\n[1] 7 3\n\n\nView Solution\nnrow(df)\n\n\n[1] 7\n\n\nView Solution\nncol(df)\n\n\n[1] 3\n\n\n\nGet summary statistics of a data frame.\n\n\n\nView Solution\nsummary(df)\n\n\n   Weight.lbs      Height.in        Gender         \n Min.   :120.0   Min.   :60.00   Length:7          \n 1st Qu.:132.5   1st Qu.:62.00   Class :character  \n Median :145.0   Median :65.00   Mode  :character  \n Mean   :147.9   Mean   :64.71                     \n 3rd Qu.:162.5   3rd Qu.:67.00                     \n Max.   :180.0   Max.   :70.00                     \n\n\n\nOperations with Matrix and Data Frame\n\n\nExtract the first row and second column of a matrix.\n\n\n\nView Solution\ndat[1,]\n\n\nweight.lbs  Height.in \n       140         65 \n\n\nView Solution\ndat[,2]\n\n\n[1] 65 60 63 66 61\n\n\n\nSubset the first two rows of a matrix\n\n\n\nView Solution\ndat[1:2,]\n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        120        60\n\n\n\nSubset rows 1,3,5 of a matrix.\n\n\n\nView Solution\ndat[c(1,3,5), ]\n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        160        63\n[3,]        125        61\n\n\n\nSelect all the Male observations from a data frame.\n\n\n\nView Solution\nsubset(df, Gender==\"Male\")\n\n\n  Weight.lbs Height.in Gender\n6        180        70   Male\n7        165        68   Male\n\n\n\nTranspose of a matrix\n\n\n\nView Solution\nA = matrix(c(3,1,2,4), ncol=2)\nA\n\n\n     [,1] [,2]\n[1,]    3    2\n[2,]    1    4\n\n\n\nMatrix multiplication\n\n\n\nView Solution\nB = matrix(c(1,2,3,4), ncol=2)\nA %*% B \n\n\n     [,1] [,2]\n[1,]    7   17\n[2,]    9   19\n\n\nView Solution\nB %*% A \n\n\n     [,1] [,2]\n[1,]    6   14\n[2,]   10   20\n\n\n\nMatrix inversion\n\n\n\nView Solution\nsolve(A)\n\n\n     [,1] [,2]\n[1,]  0.4 -0.2\n[2,] -0.1  0.3\n\n\n\n\n1.8.3 Exercise 3: Linear Algebra\nConsider the linear system A X = b, where A is an n\\times n positive definite matrix and b is a n-dimensional vector, the unique solution is X = A^{-1}b. Please answer the following questions:\n\nWrite an R function called my_solver() such that given inputs A and b, the function my_solver() returns the solution of the linear system, i.e., X &lt;- my_solver(A, b).\nRun the following code to get A and b.\n\nset.seed(123)\nA = matrix(c(5,1,1,6), ncol=2)\nn = nrow(A)\nb = rnorm(n,1)\nThen use your function my_solver() to produce the answer and verify your solution. (hint: AX should be equal to b)\n\n\nView Solution\nmy_solver &lt;- function(A, b){\n  x = solve(A, b)\n  return(x)\n}\n\nA = matrix(c(5,1,1,6), ncol=2)\nn = nrow(A)\nb = rnorm(n,1)\nx1 = my_solver(A, b)\nsum((A%*%x1-b)^2)\n\n\n[1] 1.232595e-32\n\n\n\n\n1.8.4 Exercise 4: Working with ggplot2 Package\nEPA monitors Air Quality data across the entire U.S. The file AQSdata.csv contains daily PM 2.5 concentrations and other information. Please answer the following questions using the ggplot() function for plotting. In addition make sure that all the x-axis and y-axis labels have 14 font size.\n\nRead the data file AQSdata.csv into R.\nGenerate density plots of PM2.5 concentrations grouped by County in one single panel, where each density should have its own color. What do you find from the figure?\nPlot histograms of PM2.5 concentrations across different counties with one panel for one histogram.\nGenerate boxplots of PM2.5 concentrations by County. What would you say about the distributions?\nReorder the boxplots above by the median value of PM2.5 concentrations.\nConverting the Site ID to a factor and plot the histogram grouped by Site ID.\nGenerate the time series plot for the monitoring Site ID 450190048.\nPlot time series of PM2.5 concentrations for all monitoring sites in one panel, where each site has its own color\nPlot time series of PM2.5 concentrations across all monitoring sites in multiple panels, where one panel only has one site, and each row only has two panels.\nIn the time series plot, there seems to be not enough space to hold the x-axis labels. One way to avoid this is to rotate the axis labels. Please rotate all the time labels 45 degree.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(readr)\nlibrary(lubridate)\n\ndf = read_csv(\"AQSdata.csv\")\nhead(df)\n\n\n# A tibble: 6 × 20\n  Date       Source `Site ID`   POC Daily Mean PM2.5 Con…¹ UNITS DAILY_AQI_VALUE\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;                  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n1 11/09/2021 AQS    450190020     1                   15.5 ug/m…              58\n2 11/10/2021 AQS    450190020     1                   13.6 ug/m…              54\n3 11/11/2021 AQS    450190020     1                    8.1 ug/m…              34\n4 11/12/2021 AQS    450190020     1                    7.1 ug/m…              30\n5 11/13/2021 AQS    450190020     1                   10.7 ug/m…              45\n6 11/14/2021 AQS    450190020     1                    7.5 ug/m…              31\n# ℹ abbreviated name: ¹​`Daily Mean PM2.5 Concentration`\n# ℹ 13 more variables: `Site Name` &lt;chr&gt;, DAILY_OBS_COUNT &lt;dbl&gt;,\n#   PERCENT_COMPLETE &lt;dbl&gt;, AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;,\n#   CBSA_CODE &lt;dbl&gt;, CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;,\n#   COUNTY_CODE &lt;chr&gt;, COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;\n\n\nCode\ntheme_mat = theme(axis.text = element_text(size = 14),\n                  axis.title = element_text(size = 14, face = \"bold\"))\ndf = rename(df, PM2.5 = `Daily Mean PM2.5 Concentration`)\nggplot(df) +\n  geom_freqpoly(aes(\n    x = PM2.5,\n    y = after_stat(density),\n    color = COUNTY\n  ), binwidth = 2) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = PM2.5), binwidth = .8) +\n  facet_wrap(~ COUNTY, ncol = 3) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_boxplot(aes(x = COUNTY, y = PM2.5)) +\n  xlab(\"County\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_boxplot(aes(x = reorder(COUNTY, PM2.5, FUN = median), \n                   y = PM2.5)) +\n  xlab(\"County\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\ndf1 = df\ndf1$`Site ID` =  as.factor(df$`Site ID`)\nggplot(df1) +\n  geom_freqpoly(aes(x = PM2.5, color = `Site ID`), binwidth = 2) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\ndf1 %&gt;%\n  filter(`Site ID` == 450190048) %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5)) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\ndf1 %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5, color = `Site ID`)) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\n\n\n\n\n\n\n\n\n\nCode\ng &lt;- df1 %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5)) +\n  facet_wrap(~ `Site ID`, ncol = 2) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\nprint(g)\n\n\n\n\n\n\n\n\n\nCode\ng + theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.5 Exercise 5: Working with dplyr Package\nContinuing working with the above PM 2.5 data.\n\nFilter all the observations in the county Greenville. How many observations are there?\nFilter all the observations in Greenville in August 2021\nFilter all the observations in Greenville in August 2021 and select the variables PM2.5 concentrations, Date, latitude and longitude of sites\nGenerate scatterplots of PM2.5 against latitude and longitude in two different panels\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\n\ndf %&gt;%\n  filter(COUNTY == \"Greenville\")\n\n\n# A tibble: 937 × 20\n   Date       Source `Site ID`   POC PM2.5 UNITS    DAILY_AQI_VALUE `Site Name` \n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       \n 1 01/01/2021 AQS    450450015     1   6.3 ug/m3 LC              26 Greenville …\n 2 01/02/2021 AQS    450450015     1   6.6 ug/m3 LC              28 Greenville …\n 3 01/03/2021 AQS    450450015     1   5.4 ug/m3 LC              23 Greenville …\n 4 01/05/2021 AQS    450450015     1   7.4 ug/m3 LC              31 Greenville …\n 5 01/06/2021 AQS    450450015     1   7.7 ug/m3 LC              32 Greenville …\n 6 01/07/2021 AQS    450450015     1   9.5 ug/m3 LC              40 Greenville …\n 7 01/08/2021 AQS    450450015     1   7.5 ug/m3 LC              31 Greenville …\n 8 01/09/2021 AQS    450450015     1   5.3 ug/m3 LC              22 Greenville …\n 9 01/10/2021 AQS    450450015     1  12.1 ug/m3 LC              51 Greenville …\n10 01/11/2021 AQS    450450015     1  16.7 ug/m3 LC              61 Greenville …\n# ℹ 927 more rows\n# ℹ 12 more variables: DAILY_OBS_COUNT &lt;dbl&gt;, PERCENT_COMPLETE &lt;dbl&gt;,\n#   AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;, CBSA_CODE &lt;dbl&gt;,\n#   CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;, COUNTY_CODE &lt;chr&gt;,\n#   COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;\n\n\nCode\ndf %&gt;%\n  mutate(Date = mdy(Date), YM = format_ISO8601(Date, precision = \"ym\")) %&gt;%\n  filter(COUNTY == \"Greenville\", YM == \"2021-08\")\n\n\n# A tibble: 82 × 21\n   Date       Source `Site ID`   POC PM2.5 UNITS    DAILY_AQI_VALUE `Site Name` \n   &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       \n 1 2021-08-01 AQS    450450015     1  13.8 ug/m3 LC              55 Greenville …\n 2 2021-08-02 AQS    450450015     1  19   ug/m3 LC              66 Greenville …\n 3 2021-08-03 AQS    450450015     1  16.9 ug/m3 LC              61 Greenville …\n 4 2021-08-04 AQS    450450015     1  15.6 ug/m3 LC              58 Greenville …\n 5 2021-08-05 AQS    450450015     1  11   ug/m3 LC              46 Greenville …\n 6 2021-08-06 AQS    450450015     1  10.3 ug/m3 LC              43 Greenville …\n 7 2021-08-07 AQS    450450015     1   9.7 ug/m3 LC              40 Greenville …\n 8 2021-08-08 AQS    450450015     1  10   ug/m3 LC              42 Greenville …\n 9 2021-08-09 AQS    450450015     1  12   ug/m3 LC              50 Greenville …\n10 2021-08-10 AQS    450450015     1  12.5 ug/m3 LC              52 Greenville …\n# ℹ 72 more rows\n# ℹ 13 more variables: DAILY_OBS_COUNT &lt;dbl&gt;, PERCENT_COMPLETE &lt;dbl&gt;,\n#   AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;, CBSA_CODE &lt;dbl&gt;,\n#   CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;, COUNTY_CODE &lt;chr&gt;,\n#   COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;, YM &lt;chr&gt;\n\n\nCode\ndf %&gt;%\n  mutate(Date = mdy(Date), YM = format_ISO8601(Date, precision = \"ym\")) %&gt;%\n  filter(COUNTY == \"Greenville\", YM == \"2021-08\") %&gt;%\n  dplyr::select(PM2.5, Date, SITE_LATITUDE, SITE_LONGITUDE)\n\n\n# A tibble: 82 × 4\n   PM2.5 Date       SITE_LATITUDE SITE_LONGITUDE\n   &lt;dbl&gt; &lt;date&gt;             &lt;dbl&gt;          &lt;dbl&gt;\n 1  13.8 2021-08-01          34.8          -82.4\n 2  19   2021-08-02          34.8          -82.4\n 3  16.9 2021-08-03          34.8          -82.4\n 4  15.6 2021-08-04          34.8          -82.4\n 5  11   2021-08-05          34.8          -82.4\n 6  10.3 2021-08-06          34.8          -82.4\n 7   9.7 2021-08-07          34.8          -82.4\n 8  10   2021-08-08          34.8          -82.4\n 9  12   2021-08-09          34.8          -82.4\n10  12.5 2021-08-10          34.8          -82.4\n# ℹ 72 more rows\n\n\nCode\ndf %&gt;%\n  dplyr::select(PM2.5, SITE_LATITUDE, SITE_LONGITUDE) %&gt;%\n  pivot_longer(\n    cols = c(\"SITE_LATITUDE\", \"SITE_LONGITUDE\"),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  ggplot(aes(x = value, y = PM2.5)) +\n  geom_point() +\n  facet_wrap( ~ variable, scale = \"free\") +\n  xlab(\"\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#introduction",
    "href": "ch2/02-graphs.html#introduction",
    "title": "2  Graphs and Data Visualization",
    "section": "",
    "text": "Graphs reveal information about the center, shape, and spread of distributions.\nThey can also show typical and extreme outcomes, associations, and differences between groups.\nDifferent data types require different graph types.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#categorical-data",
    "href": "ch2/02-graphs.html#categorical-data",
    "title": "2  Graphs and Data Visualization",
    "section": "2.2 Categorical Data",
    "text": "2.2 Categorical Data\nCategorical data types:\n\nNominal: no natural order (e.g., eye color, blood type).\nOrdinal: ordered, but spacing not meaningful (e.g., therapy response).\nInterval: ordered and evenly spaced (e.g., fruit count).\n\n\n2.2.1 Bar Chart Example\nBar chart is used for displaying categorical variables.\n\n\nR Code: Bart Chart\ncolors &lt;- c('Red', 'Pink', 'White')\ncounts &lt;- c(80, 60, 40)\nbar_df &lt;- data.frame(Color = colors, Count = counts)\nggplot(bar_df, aes(x = Color, y = Count)) +\n  geom_bar(stat = 'identity', fill = 'steelblue') +\n  theme_minimal() +\n  labs(title = 'Poinsettia Colors')\n\n\n\n\n\n\n\n\n\n\nQuestion: What does the bar plot tell you about the color distribution for this poinsettia variety?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#quantitative-data",
    "href": "ch2/02-graphs.html#quantitative-data",
    "title": "2  Graphs and Data Visualization",
    "section": "2.3 Quantitative Data",
    "text": "2.3 Quantitative Data\n\nMeasured on a numeric scale: e.g., weights, heights, cholesterol levels.\nUse histograms, boxplots, dotplots, density plots.\n\n\n2.3.1 Histogram Example (Tip Amounts)\nHistograms classify values into bins of equal width\n\nHeights of bars represent relative frequencies\n\n\n\nR Code: Histogram\ndata(\"tips\", package=\"reshape2\")\nggplot(tips, aes(x = tip)) +\n  geom_histogram(binwidth = 1, fill = 'orange', color = 'black') +\n  theme_minimal() +\n  labs(title = 'Histogram of Tip Amounts', x = 'Tip ($)', y = 'Count')\n\n\n\n\n\n\n\n\n\n\nQuestion: What does this histogram tell you about tips at this restaurant?\n\n\n\n\n\n\n\nTip\n\n\n\n\nCenter\nShape\nSpread\n\n\n\n\n\n2.3.2 Try Different Bin Widths\n\n\nR Code: Histograms with Different Bin Widths\nbw_list &lt;- c(0.25, 0.5, 1.0)\nplots &lt;- lapply(bw_list, function(bw) {\n  ggplot(tips, aes(x = tip)) +\n    geom_histogram(binwidth = bw, fill = 'lightblue', color = 'black') +\n    ggtitle(paste('Bin Width =', bw)) +\n    theme_minimal()\n})\nlibrary(gridExtra)\ndo.call(grid.arrange, c(plots, ncol = 1))\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Boxplot\nBoxplot is graphical display of the five number data summary (minimum, Q1, median, Q3, maximum). It is good for comparing samples from different populations.\n\n\nR Code: Boxplot\nggplot(tips, aes(y = tip)) +\n  geom_boxplot(fill = 'lightgreen') +\n  theme_minimal() +\n  labs(title = 'Boxplot of Tip Amounts', y = 'Tip ($)')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#one-quantitative-one-categorical",
    "href": "ch2/02-graphs.html#one-quantitative-one-categorical",
    "title": "2  Graphs and Data Visualization",
    "section": "2.4 One Quantitative & One Categorical",
    "text": "2.4 One Quantitative & One Categorical\nSide by side box plots and dot plots can be used to compare distributions of a quantitative response variable for different levels of a categorical variable.\n\n\nR Code: Boxplots with Grouping\nggplot(tips, aes(x = day, y = tip)) +\n  geom_boxplot(fill = 'skyblue') +\n  theme_minimal() +\n  labs(title = 'Tip Amount by Day of Week')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-variables",
    "href": "ch2/02-graphs.html#two-quantitative-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.5 Two Quantitative Variables",
    "text": "2.5 Two Quantitative Variables\nScatterplots convey information about associations between quantitative variables and also about unusual observations.\n\n\nR Code: Scatterplot\ntips$bill &lt;- tips$total_bill\nggplot(tips, aes(x = bill, y = tip)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE, col = 'red') +\n  theme_minimal() +\n  labs(title = 'Tip vs Bill Amount', x = 'Bill ($)', y = 'Tip ($)')\n\n\n\n\n\n\n\n\n\n\nHow is the tip related to the bill?\nWhich variable is the response? Which is the explanatory variable?\nWhat type of relationship would you expect?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#practice-problems",
    "href": "ch2/02-graphs.html#practice-problems",
    "title": "2  Graphs and Data Visualization",
    "section": "2.6 Practice Problems",
    "text": "2.6 Practice Problems\n\n2.6.1 Exercise 1: Bar Chart from Survey\nCreate a bar chart for the following survey results:\n\n\n\nPet Type\nCount\n\n\n\n\nDog\n15\n\n\nCat\n10\n\n\nFish\n3\n\n\nBird\n2\n\n\n\nUse ggplot2 package to visualize the data and describe what the chart tells you about pet preferences.\n\n\nView Solution\nlibrary(ggplot2)\npet_df &lt;- data.frame(\n  Pet = c(\"Dog\", \"Cat\", \"Fish\", \"Bird\"),\n  Count = c(15, 10, 3, 2)\n)\nggplot(pet_df, aes(x = Pet, y = Count, fill = Pet)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Pet Types\", x = \"Pet Type\", y = \"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\n2.6.2 Exercise 2: Simulated Histogram\nSimulate 300 observations from a normal distribution with mean 70 and standard deviation 10.\n\nPlot a histogram using binwidth = 5 and 10.\nOverlay a density curve using geom_density().\nDescribe the center, spread, and shape of the distribution.\n\n\n\nView Solution\nset.seed(4750)\nx &lt;- rnorm(300, mean = 70, sd = 10)\n# Histogram with binwidth 5\np1 &lt;- ggplot(data.frame(x), aes(x = x)) +\n  geom_histogram(\n    binwidth = 5,\n    fill = \"skyblue\",\n    color = \"white\",\n    alpha = 0.7\n  ) +\n  geom_density(aes(y = after_stat(count) * 5),\n               color = \"red\",\n               linewidth = 1.2) +\n  labs(title = \"Histogram (binwidth = 5) with Density\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\n# Histogram with binwidth 10\np2 &lt;- ggplot(data.frame(x), aes(x = x)) +\n  geom_histogram(\n    binwidth = 10,\n    fill = \"orange\",\n    color = \"white\",\n    alpha = 0.7\n  ) +\n  geom_density(aes(y =  after_stat(count) * 10),\n               color = \"red\",\n               linewidth = 1.2) +\n  labs(title = \"Histogram (binwidth = 10) with Density\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\nlibrary(patchwork)\np1 / p2\n\n\n\n\n\n\n\n\n\n\n\n2.6.3 Exercise 3: Boxplots by Group\nSimulate exam scores for two groups of students (Group A and Group B), each with 50 observations.\n\nGenerate scores from rnorm(50, mean=80, sd=5) for Group A and rnorm(50, mean=75, sd=7) for Group B.\nCreate a combined data.frame and make a boxplot comparing the two groups.\nInterpret differences in central tendency and variability.\n\n\n\nView Solution\nset.seed(4750)\ngroup_a &lt;- rnorm(50, mean = 80, sd = 5)\ngroup_b &lt;- rnorm(50, mean = 75, sd = 7)\n\nscores &lt;- data.frame(\n  Score = c(group_a, group_b),\n  Group = rep(c(\"A\", \"B\"), each = 50)\n)\n\nlibrary(ggplot2)\nggplot(scores, aes(x = Group, y = Score, fill = Group)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Exam Scores by Group\", y = \"Score\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nCentral tendency: Group A has a higher median and mean score than Group B.\nVariability: Group B shows a wider spread (greater interquartile range and more outliers) compared to Group A, which aligns with the larger standard deviation used in its simulation.\n\n\n\n2.6.4 Exercise 4: Scatterplot with Regression\nSimulate a dataset of 100 observations where x ~ runif(100, 0, 100) and y = 0.5 * x + rnorm(100, 0, 5).\n\nCreate a scatterplot of y vs x.\nAdd a regression line.\nDescribe the relationship and interpret the slope.\n\n\n\nView Solution\nset.seed(4750)\nx &lt;- runif(100, 0, 100)\ny &lt;- 0.5 * x + rnorm(100, 0, 5)\ndata &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(title = \"Scatterplot of y vs x with Regression Line\",\n       x = \"x\",\n       y = \"y\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nThere is a strong positive linear relationship between x and y, as expected from the model.\nThe slope of the regression line is close to 0.5, indicating that, on average, each 1-unit increase in x results in a 0.5-unit increase in y.\nThe scatter around the regression line reflects the normal error term with standard deviation 5.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-one-categorical",
    "href": "ch2/02-graphs.html#two-quantitative-one-categorical",
    "title": "2  Graphs and Data Visualization",
    "section": "2.7 Two Quantitative & One Categorical",
    "text": "2.7 Two Quantitative & One Categorical\n\nGrouping: a graph consisting of a single panel with multiple variables differentiated using different visual characteristics such as color, shape, and size.\nFaceting: a graph consisting of several separate panels, with one for each level of the faceted variable, or combination of two faceted variables.\n\n\n\nR Code: Grouping\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = 'lm', se = FALSE) +\n  labs(title = 'Tip vs Bill by Gender')\n\n\n\n\n\n\n\n\n\n\n\nR Code: Faceting\nggplot(tips, aes(x=bill, y=tip)) + \n  geom_point(alpha=0.6) + \n  geom_smooth(method = 'lm', se = FALSE) + \n  facet_wrap(~ sex, ncol=2) + \n  labs(title = 'Tip vs Bill by Gender')\n\n\n\n\n\n\n\n\n\n\nDoes the relationship differ for men and women?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-two-categorical-variables",
    "href": "ch2/02-graphs.html#two-quantitative-two-categorical-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.8 Two Quantitative & Two Categorical Variables",
    "text": "2.8 Two Quantitative & Two Categorical Variables\n\n\nR Code: Grouping + Faceting\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(smoker ~ .) +\n  labs(title = \"Tip vs Bill by Sex and Smoking Status\",\n       x = \"Bill ($)\", y = \"Tip ($)\")\n\n\n\n\n\n\n\n\n\n\n\nR Code: Faceting Only\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(smoker ~ sex) +\n  labs(title = \"Tip vs Bill by Sex and Smoking Status\",\n       x = \"Bill ($)\", y = \"Tip ($)\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#three-variables",
    "href": "ch2/02-graphs.html#three-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.9 Three Variables",
    "text": "2.9 Three Variables\n\n2.9.1 3D Scatterplot\n\n\nCode\nlibrary(plotly)\ndata(mtcars)\n# Example with mtcars\nplot_ly(\n  data = mtcars,\n  x = ~mpg, y = ~hp, z = ~wt,\n  type = 'scatter3d',\n  mode = 'markers',\n  color = ~as.factor(cyl)\n)\n\n\n\n\n\n\n\n\n2.9.2 Bubble Chart\n\n\nCode\nggplot(mtcars, \n       aes(x=mpg, y=hp, size=wt)) + \n  geom_point(alpha=.5, \n             fill=\"red\", \n             color=\"black\",\n             shape=21) + \n  scale_size_continuous(range = c(1, 5))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#scatterplot-matrix",
    "href": "ch2/02-graphs.html#scatterplot-matrix",
    "title": "2  Graphs and Data Visualization",
    "section": "2.10 Scatterplot Matrix",
    "text": "2.10 Scatterplot Matrix\nA scatterplot matrix (sometimes called a “pairs plot”) is used to visualize the pairwise relationships between several quantitative variables in a dataset, all at once.\n\nEach row and column represents one variable.\nThe off-diagonal panels show scatterplots for each pair of variables (e.g., x vs y, x vs z, y vs z).\nThe diagonal often shows the distribution of each variable (as a histogram, density, or boxplot).\nYou can optionally color points by a group or class variable.\n\n\n\nR Code: Scatterplot Matrix\ndata(mtcars)\nlibrary(GGally)\nGGally::ggpairs(\n  mtcars,\n  columns = c(\"mpg\", \"hp\", \"wt\")\n)\n\n\n\n\n\n\n\n\n\n\n\nScatterplot Matrix with Base R\npairs(mtcars[,c(\"mpg\", \"hp\", \"wt\")])\n\n\n\n\n\n\n\n\n\n\n\nR Code: Sample Correlation\ncor(mtcars[,c(\"mpg\", \"hp\", \"wt\")])\n\n\n           mpg         hp         wt\nmpg  1.0000000 -0.7761684 -0.8676594\nhp  -0.7761684  1.0000000  0.6587479\nwt  -0.8676594  0.6587479  1.0000000",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#parallel-coordinates",
    "href": "ch2/02-graphs.html#parallel-coordinates",
    "title": "2  Graphs and Data Visualization",
    "section": "2.11 Parallel Coordinates",
    "text": "2.11 Parallel Coordinates\nA parallel coordinates plot is a powerful visualization tool used for exploring and comparing multivariate data (data with several quantitative variables). It’s especially valuable when you want to see how patterns, clusters, or outliers appear across many variables at once.\n\n\nR Code: Parallel Coordinates Plot\n# Convert cyl to factor for coloring\nmtcars$cyl &lt;- as.factor(mtcars$cyl)\n\nGGally::ggparcoord(\n  mtcars,\n  columns = c(1,4,6), # mpg, hp, wt\n  groupColumn = \"cyl\",\n  scale = \"uniminmax\",    # Normalize to [0,1] for fair comparison\n  showPoints = TRUE,\n  alphaLines = 0.6\n) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Cylinders\") +\n  labs(title = \"Parallel Coordinates Plot: mtcars (by cylinders)\")\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nEach line is a car.\nThe color indicates the number of cylinders.\nCars with more cylinders generally have lower mpg and higher hp and weight.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html#exercises",
    "href": "ch2/02-graphs.html#exercises",
    "title": "2  Graphs and Data Visualization",
    "section": "2.12 Exercises",
    "text": "2.12 Exercises\n\n2.12.1 Exercise 1: Ames Housing Data\nLoad the Ames Housing data into R and answer the following questions:\n\nAmes = read.csv(\"Ameshousing.csv\")\nhead(Ames)\n\n  SalePrice Bedrooms LotArea LivingArea GarageArea Neighborhood\n1    270000        4   11792       2283        632      Gilbert\n2    377500        3   14892       1746        758      Gilbert\n3    337500        3   12456       1718        786      NridgHt\n4    462000        4   14257       2772        754      NridgHt\n5    489900        2   14803       2084       1220      NridgHt\n6    555000        2   15431       2402        672      NridgHt\n\n\n\nSummary Statistics\n\n\nHow many homes were included in this study?\n\nWhat are the names of the variables for which information was collected?\nCompute the median living area, the mean living area and the standard error for the mean living area for all of the houses in the data set.\nCompute the median living area, the mean living area and the standard error for the mean living area for the houses in each neighborhood.\nCompute the number of houses, mean sale price and the standard error of the mean sale price for houses with living areas less than 1800 square feet.\nSummarize in a paragraph the information in the correlation matrix about associations between sales price, lot size, living area, garage area, and number of rooms from the sample correlation matrix.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\ndim(Ames)[1]\n\n\n[1] 168\n\n\n\n\nCode\nnames(Ames)\n\n\n[1] \"SalePrice\"    \"Bedrooms\"     \"LotArea\"      \"LivingArea\"   \"GarageArea\"  \n[6] \"Neighborhood\"\n\n\n\n\nCode\nmean_LivingArea &lt;- mean(Ames$LivingArea)\nmean_LivingArea\n\n\n[1] 1700.107\n\n\nCode\nmedian_LivingArea &lt;- median(Ames$LivingArea)\nsderr_LivingArea &lt;- sd(Ames$LivingArea)/ sqrt(length(Ames$LivingArea))\nsderr_LivingArea\n\n\n[1] 32.32775\n\n\n\n\nCode\nmean_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, mean)\nmean_LivingArea\n\n\n CollgCr  Gilbert  NridgHt \n1565.921 1658.966 1880.921 \n\n\nCode\nmedian_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, median)\nmedian_LivingArea\n\n\nCollgCr Gilbert NridgHt \n 1591.5  1560.0  1743.0 \n\n\nCode\nsd_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, sd)\nsderr_LivingArea &lt;- sd_LivingArea / sqrt(tapply(Ames$LivingArea, Ames$Neighborhood, length))\nsderr_LivingArea\n\n\n CollgCr  Gilbert  NridgHt \n42.72812 56.21652 57.40376 \n\n\n\n\nCode\nAmes2 &lt;- Ames[ Ames$LivingArea&lt;1800, ]\nn &lt;- dim(Ames2)[1]\ncat(\"number of houses with living area &lt; 1800: \", n)\n\n\nnumber of houses with living area &lt; 1800:  116\n\n\n\n\nCode\nmean_Saleprice &lt;- mean(Ames2$SalePrice)\ncat(\"Mean Sale Price for Houses with Living Area &lt; 1800: \", mean_Saleprice)\n\n\nMean Sale Price for Houses with Living Area &lt; 1800:  215756.7\n\n\n\n\nCode\nsderr_SalePrice &lt;- sd(Ames2$SalePrice)/ sqrt(length(Ames2$SalePrice))\ncat(\"Stderror for Mean Sale Price: \", sderr_SalePrice)\n\n\nStderror for Mean Sale Price:  4693.031\n\n\n\n\n\n\nGraphical Summaries\n\n\nCreate a scatterplot with a smooth curve passed through the points.\nFit a least squares regression line to the data in the plot.\nWhat does the regression line indicate about sales prices of houses increase with living area?\nWhat information is provided by the plot with smooth curve?\nAdd a new variable to the data frame that contains information on sales price divided by the living area in the house, i.e., the sales price per square foot of living area.\nCreate a histogram for the price per square foot of living space.\nWhat does this histogram reveal about the distribution of costs per square foot of living space for houses sold in the Ames area? The description should be based on the shape, center and spread of the distribution.\nCreate separate plots of sales prices versus living space categorized for each neighborhood\nConstruct side-by-side box plots to compare prices per square foot of living space across neighborhoods.\nDescribe the relationship between sales price and total living area of house changes across the three neighborhoods.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n    geom_point(alpha=.7) + \n    geom_smooth() + \n    labs(\n      x=\"Living Area (sq ft)\",\n      y=\"Sale Price (dollars)\",\n      title=\"Sale Price vs Total Living Area\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlm(SalePrice ~ LivingArea, data = Ames)\n\n\n\nCall:\nlm(formula = SalePrice ~ LivingArea, data = Ames)\n\nCoefficients:\n(Intercept)   LivingArea  \n   -21769.1        159.5  \n\n\nCode\nplot( Ames$LivingArea, Ames$SalePrice, \n      xlab=\"Living Area (sq ft)\", \n      ylab=\"Sale Price (dollars)\",\n      main = \"Sale Price vs Total Living Area\")\nabline(lm(SalePrice~LivingArea, data=Ames), lty=1)\n\n\n\n\n\n\n\n\n\n\nThe slope of the regression suggests that the mean sale price of homes in the Ames area goes up by about 159.50 dollars for each additional square foot of living space.\nThe smooth curve indicates that there is an approximate straight line relationship between the mean home price and the living area of homes for homes with between 800 and 2000 square feet of living area, but the relationship curves up for larger home sizes. Also the variation in sale prices tends to increase with the amount of living area in the house.\n\n\n\nCode\nAmes$pricesqft  &lt;-  Ames$SalePrice/Ames$LivingArea \nhead(Ames)\n\n\n  SalePrice Bedrooms LotArea LivingArea GarageArea Neighborhood pricesqft\n1    270000        4   11792       2283        632      Gilbert  118.2654\n2    377500        3   14892       1746        758      Gilbert  216.2085\n3    337500        3   12456       1718        786      NridgHt  196.4494\n4    462000        4   14257       2772        754      NridgHt  166.6667\n5    489900        2   14803       2084       1220      NridgHt  235.0768\n6    555000        2   15431       2402        672      NridgHt  231.0575\n\n\n\n\nCode\nAmes %&gt;% ggplot() + \n  geom_histogram(aes(pricesqft), binwidth =20) \n\n\n\n\n\n\n\n\n\n\nThis histogram indicates that the distribution of costs per square foot of living space for houses sold in the Ames area is centered around $145 per square foot. The distribution is skewed to the right and it appears to be bimodal with one mode around $125 per square foot and another near $165 pre sqaure foot. Most houses cost between $100 and $200 per square foot of living space.\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n  geom_point() + \n  geom_smooth() + \n  facet_grid( . ~ Neighborhood) + \n  labs(\n    x=\"Living Area (sq ft)\",\n    y=\"Sale Price (dollars)\",\n    title=\"Sales Price vs Total Living Area\"\n  )\n\n\n\n\n\n\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n  geom_point() + \n  geom_smooth() + \n  facet_grid(Neighborhood ~ .) + \n  labs(\n    x=\"Living Area (sq ft)\",\n    y=\"Sale Price (dollars)\",\n    title=\"Sales Price vs Total Living Area\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=Neighborhood, y=pricesqft)) + \n  geom_boxplot() + \n  labs(y=\"Sales Price per Square Foot\")\n\n\n\n\n\n\n\n\n\n\nIn all three neighborhoods sales prices tend to be larger for house with more living area. In the College Circle (CollgCr) and Northridge Heights (NridgHt) neighborhoods, there are strong linear relationships between these two variables. Because the slope is larger for houses in the Northridge Heights neighborhood, the price per square foot of living space is higher. There are more expensive houses in the Northridge Heights neighborhood. In Gilbert, the trend in sales prices is not so close to a straight line. There is little trend in sales prices for houses with less than 1,750 square feet of living space. There is also little trend in the sales prices for houses with living space above 1,900 square feet, but those houses are more expensive than house with less then 17,50 square feet. There is one relatively expensive house with about 1,750 square feet of living space that appears to be an outlier. Perhaps this house has an extremely large lot size or some additional buildings on the property. This should be investigated.\n\n\n\n\n\n\n2.12.2 Exercise 2: Music Clips Data\nThe music clips data is posted in music-plusnew-sub.csv. The data file has five quantitative variables containing audio information from 62 songs. The first two columns (Artist, Type) describe the artist and type of music. The raw data come from a time series for the sound produced by each music clip (track). For each time series the variance of amplitude, average amplitude, maximum amplitude, and two additional variables calculated from the spectral decomposition of the time series are calculated. The Type variable classifies the tracks as either Rock, Classical or New Wave, and there are 5 tracks that are not identified.\n\nRead the data into a data frame, indicating that the row names are in column 1 of the data file and that column is not a variable.\nObtain information on the dimensions of the data frame. Also list the column names. List the first six columns odf data.\nFirst select a subset of the data that contains only classical and rock music.\nFor classical and rock music make histograms for the avergae amplitude variable (LAve) faceted by Type. Set the binwidth to units of 10. How do the distributions of average amplitude values differ between classical and rock music?\nMake a scatterplot of LVar vs LAve, with points colored by the type of music. Describe differences between the patterns of the points on the plot corresponding to Rock and Classical music.\nSelect three music types. The other songs have missing values for the music type.\nMake a parallel coordinate plot\nReorder how the variables appear on the plot.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\ndat = read.csv(\"music-plusnew-sub.csv\", row.names=1)  \n\nhead(dat) \n\n\n              Artist Type     LVar      LAve  LMax   LFEner     LFreq\nDancing Queen   Abba Rock 17600756 -90.00687 29921 105.9210  59.57379\nKnowing Me      Abba Rock  9543021 -75.76672 27626 102.8362  58.48031\nTake a Chance   Abba Rock  9049482 -98.06292 26372 102.3249 124.59397\nMamma Mia       Abba Rock  7557437 -90.47106 28898 101.6165  48.76513\nLay All You     Abba Rock  6282286 -88.95263 27940 100.3008  74.02039\nSuper Trouper   Abba Rock  4665867 -69.02084 25531 100.2485  81.40140\n\n\nCode\nstr(dat)\n\n\n'data.frame':   62 obs. of  7 variables:\n $ Artist: chr  \"Abba\" \"Abba\" \"Abba\" \"Abba\" ...\n $ Type  : chr  \"Rock\" \"Rock\" \"Rock\" \"Rock\" ...\n $ LVar  : num  17600756 9543021 9049482 7557437 6282286 ...\n $ LAve  : num  -90 -75.8 -98.1 -90.5 -89 ...\n $ LMax  : int  29921 27626 26372 28898 27940 25531 14699 8928 22962 15517 ...\n $ LFEner: num  106 103 102 102 100 ...\n $ LFreq : num  59.6 58.5 124.6 48.8 74 ...\n\n\nCode\nsummary(dat)\n\n\n    Artist              Type                LVar                LAve        \n Length:62          Length:62          Min.   :   293608   Min.   :-98.063  \n Class :character   Class :character   1st Qu.:  2844213   1st Qu.: -6.253  \n Mode  :character   Mode  :character   Median :  8210359   Median : -5.662  \n                                       Mean   : 19951792   Mean   : -7.807  \n                                       3rd Qu.: 24547475   3rd Qu.:  1.962  \n                                       Max.   :129472199   Max.   :216.232  \n      LMax           LFEner           LFreq       \n Min.   : 2985   Min.   : 83.88   Min.   : 41.41  \n 1st Qu.:16200   1st Qu.:101.69   1st Qu.: 99.18  \n Median :24431   Median :104.35   Median :175.29  \n Mean   :22486   Mean   :104.03   Mean   :231.39  \n 3rd Qu.:29918   3rd Qu.:108.15   3rd Qu.:315.12  \n Max.   :32766   Max.   :114.00   Max.   :877.77  \n\n\nCode\ntable(dat$Type)\n\n\n\nClassical  New wave      Rock \n       24         3        30 \n\n\nCode\ndf.sub = dat %&gt;% \n  dplyr::filter(Type==\"Rock\" | Type==\"Classical\")\n\nggplot(df.sub, aes(LAve)) + \n  geom_histogram(binwidth=10) + \n  facet_wrap( ~ Type, ncol=1)\n\n\n\n\n\n\n\n\n\nCode\nggplot(df.sub, aes(x=LVar, y=LAve, color=Type)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nCode\ndat2 = dat %&gt;% \n  filter(Type==\"Rock\" | Type==\"Classical\" | Type==\"New wave\")\nhead(dat2)\n\n\n              Artist Type     LVar      LAve  LMax   LFEner     LFreq\nDancing Queen   Abba Rock 17600756 -90.00687 29921 105.9210  59.57379\nKnowing Me      Abba Rock  9543021 -75.76672 27626 102.8362  58.48031\nTake a Chance   Abba Rock  9049482 -98.06292 26372 102.3249 124.59397\nMamma Mia       Abba Rock  7557437 -90.47106 28898 101.6165  48.76513\nLay All You     Abba Rock  6282286 -88.95263 27940 100.3008  74.02039\nSuper Trouper   Abba Rock  4665867 -69.02084 25531 100.2485  81.40140\n\n\nCode\nGGally::ggparcoord(dat2, columns=3:7,\n                   groupColumn = \"Type\",\n                   title=\"Parallel Coordinate Plot: Music Types\")\n\n\n\n\n\n\n\n\n\nCode\nGGally::ggparcoord(dat2, columns=c(4,3,5,6,7),\n                   groupColumn = \"Type\",\n                   title=\"Parallel Coordinate Plot: Music Types\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html",
    "href": "ch3/03-MVN.html",
    "title": "3  Multivariate Normal Distribution",
    "section": "",
    "text": "3.1 Why Multivariate Normal?\nThe univariate normal distribution is fundamental in statistics. But real data usually involve multiple variables measured on the same subjects, and these are often correlated.\nRecall that if a random variable X has a normal distribution with mean \\mu and variance \\sigma^2, its density function has the form \nf(x) = \\frac{1}{ \\sqrt{2 \\pi } \\sigma} \\exp \\left\\{-\\frac{1}{2\\sigma^2} (x - \\mu)^2 \\right\\}, \\;\\;\\;\\; -\\infty &lt; x &lt; \\infty.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#why-multivariate-normal",
    "href": "ch3/03-MVN.html#why-multivariate-normal",
    "title": "3  Multivariate Normal Distribution",
    "section": "",
    "text": "Height and weight of students, or exam scores in different subjects.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#sec-matrix-background",
    "href": "ch3/03-MVN.html#sec-matrix-background",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.2 Matrix Background",
    "text": "3.2 Matrix Background\n\nThe inverse of a p\\times p matrix A is denoted by A^{-1}.\nif A^{-1} exists, A^{-1} is the unique matrix such that      AA^{-1} = A^{-1}A = I  =  \\left[ \\begin{array}{ccccc}  1 & 0 & \\cdots & 0 & 0 \\\\\n                                                              0 & 1 & \\cdots & 0 & 0  \\\\   \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                                                              0 & 0 & \\cdots & 1 & 0  \\\\ 0 & 0 & \\cdots & 0 & 1  \\end{array} \\right]\n\n\nA is said to be symmetric if A is the same as its transpose, i.e., A=A^\\top or A = A'.\nA is said to be positive definite if \n\\left[ \\begin{array}{cccc} x_1 & x_2 & \\cdots & x_p \\end{array} \\right]\nA\n\\left[ \\begin{array}{c} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_p \\end{array} \\right]\n&gt; 0 \\quad \\text{for any} \\quad\n\\left[ \\begin{array}{cccc} x_1 & x_2 & \\cdots & x_p \\end{array} \\right] \\neq \\mathbf{0}\n\nIf A is positive definite, then A^{-1} exists.\n\n\n\n\n\n\n\nExercise: Matrix Algebra\n\n\n\n\n\n\nA = matrix(c(2,1,1,4), ncol=2, byrow=TRUE)\nA\n\n     [,1] [,2]\n[1,]    2    1\n[2,]    1    4\n\n\n\n\nR Code: Scalar-matrix multiplication\na = 2 \na * A\n\n\n     [,1] [,2]\n[1,]    4    2\n[2,]    2    8\n\n\n\n\nR Code: Matrix-matrix addition\nB = matrix(c(1,2,2,9), ncol=2, byrow=TRUE)\nA + B \n\n\n     [,1] [,2]\n[1,]    3    3\n[2,]    3   13\n\n\n\n\nR Code: Matrix-vector multiplication\nx = c(1,2)\nA %*% x \n\n\n     [,1]\n[1,]    4\n[2,]    9\n\n\n\n\nR Code: Matrix-matrix multiplication\nA %*% B \n\n\n     [,1] [,2]\n[1,]    4   13\n[2,]    9   38\n\n\n\n\nR Code: Matrix inversion\n# matrix inversion\nsolve(A)\n\n\n           [,1]       [,2]\n[1,]  0.5714286 -0.1428571\n[2,] -0.1428571  0.2857143\n\n\nR Code: Matrix inversion\n# check result\nA %*% solve(A)\n\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n\n\n\n\n\n3.2.1 Eigenvalues and Eigenvectors\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a p \\times p square matrix A, an eigenvector \\mathbf{v} and its corresponding eigenvalue \\lambda satisfy: A \\mathbf{v} = \\lambda \\mathbf{v}\n\n\nInterpretation: Multiplying A by its eigenvector \\mathbf{v} simply stretches or shrinks \\mathbf{v} by a factor \\lambda—the direction of \\mathbf{v} does not change.\n\nWhy Do They Matter?\n\nEigenvectors show the principal directions in which A stretches or compresses the space.\nIn statistics, the eigenvectors of a covariance matrix gives the directions of maximum variance.\nThe corresponding eigenvalues tell you how much variance there is in each direction as explained below.\n\nSome Properties\n\nIf (\\lambda_j, \\mathbf{e}_j) is an eigenvalue-eigenvector pair for a p \\times p matrix A, by definition A \\mathbf{e}_j = \\lambda_j \\mathbf{e}_j.\nEigenvectors are usually scaled to have length one, i.e., 1=\\mathbf{e}_j^{\\top} \\mathbf{e}_j = e_{j1}^2+e_{j2}^2 + \\cdots + e_{jp}^2.\nEigenvectors are mutually orthogonal, i.e., \\mathbf{e}_j^{\\top} \\mathbf{e}_k = 0 for any j \\ne k.\n(\\lambda_j^{-1}, \\mathbf{e}_j) is an eigenvalue-eigenvector pair of A^{-1} when A is positive definite and A^{-1} exists.\n\n\n\n\n3.2.2 Spectral Decomposition\n\n\n\n\n\n\nSpectral decomposition\n\n\n\nFor any p\\times p symmetric matrix A, its spectral decomposition is  A = \\lambda_1 \\mathbf{e}_1 \\mathbf{e}_1^{\\top} +  \\lambda_2 \\mathbf{e}_2 \\mathbf{e}_2^{\\top} +  \\cdots +  \\lambda_p \\mathbf{e}_p \\mathbf{e}_p^{\\top}\n\n\n\n\nIf A^{-1} exists, then A^{-1} = \\lambda_1^{-1} \\mathbf{e}_1 \\mathbf{e}_1^{\\top} +  \\lambda_2^{-1} \\mathbf{e}_2 \\mathbf{e}_2^{\\top} +  \\cdots +  \\lambda_p^{-1} \\mathbf{e}_p \\mathbf{e}_p^{\\top}.\nA^{1/2} = \\lambda_1^{1/2} \\mathbf{e}_1 \\mathbf{e}_1^{\\top} +  \\lambda_2^{1/2} \\mathbf{e}_2 \\mathbf{e}_2^{\\top} +  \\cdots +  \\lambda_p^{1/2} \\mathbf{e}_p \\mathbf{e}_p^{\\top}\nA^{-1/2} = \\lambda_1^{-1/2} \\mathbf{e}_1 \\mathbf{e}_1^{\\top} +  \\lambda_2^{-1/2} \\mathbf{e}_2 \\mathbf{e}_2^{\\top} +  \\cdots +  \\lambda_p^{-1/2} \\mathbf{e}_p \\mathbf{e}_p^{\\top}\nA^{1/2} A^{1/2} = A and A^{-1/2}A^{-1/2}=A^{-1}.\n\n\n\nR Code: Create a Matrix\nA = matrix(c(4, 2, 1, 3), nrow = 2)\n\n\n\n\nR Code: Spectral Decomposition\neig = eigen(A)\nprint(eig)\n\n\neigen() decomposition\n$values\n[1] 5 2\n\n$vectors\n          [,1]       [,2]\n[1,] 0.7071068 -0.4472136\n[2,] 0.7071068  0.8944272\n\n\n\n\n3.2.3 Determinant of a p\\times p matrix\n\nThe determinant of the matrix A is denoted by |A| or \\text{det}(A).\nThe determinant of a p \\times p matrix is the product of its eigenvalues, i.e., |A| = \\text{det}(A) = \\lambda_1 \\lambda_2 \\cdots \\lambda_p.\nAll of the eigenvalues of a positive definite matrix are positive.\nThe determinant of a positive definite matrix must be larger than zero.\nIf at least one eigenvalue is zero and the inverse of the matrix does not exist, then the determinant of the matrix is zero.\n\n\n\nMatrix Determinant: det for Small Matrices\ndet(A) \n\n\n[1] 10\n\n\n\n\nMatrix Determinant: Eigen Decomposition\nE = eigen(A)\nprod(E$values)\n\n\n[1] 10",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#probability-density-function-of-mvn",
    "href": "ch3/03-MVN.html#probability-density-function-of-mvn",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.3 Probability Density Function of MVN",
    "text": "3.3 Probability Density Function of MVN\nThe multivariate normal distribution (MVN) generalizes the univariate normal distribution to multiple variables.\nA random vector \\mathbf{x} = (x_1, x_2, \\ldots, x_p)^\\top follows a multivariate normal distribution if every linear combination of its components is normal. We use the notation: \n\\mathbf{x} \\sim N_p(\\boldsymbol{\\mu}, {\\Sigma}) \\quad\n\\text{ or }\\quad \\mathbf{x} \\sim \\text{MVN}(\\boldsymbol\\mu, \\Sigma)\n where\n\n\\boldsymbol{\\mu}:=(\\mu_1, \\mu_2, \\ldots, \\mu_p)^\\top is the p-dimensional mean vector\nand \\Sigma = \\left[ \\begin{array}{cccc} \\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1p} \\\\  \\sigma_{21} & \\sigma_{22} & \\cdots \\  & \\sigma_{2p} \\\\  \\vdots & \\vdots & \\ddots & \\vdots \\\\  \\sigma_{p1} & \\sigma_{p2} & \\cdots & \\sigma_{pp} \\end{array} \\right]  is the p \\times p covariance matrix of \\mathbf{x}.\n\n\n\n\n\n\n\nProbability Density Function (PDF)\n\n\n\nThe probability density function for \\mathbf{x} \\sim N_p(\\boldsymbol \\mu, \\Sigma) is \nf(\\mathbf{x}) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol\\mu)^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu)\\right)\n\nGeometric Interpretation:\n\n\\boldsymbol{\\mu}: The center of the point cloud.\n{\\Sigma}: Controls the spread and orientation.\n\nDiagonal = variances\nOff-diagonal = covariances (correlation/shape)\n\n\n\n\n\n\n\n\n\n\nMahalanobis Distance\n\n\n\nThe quadratic form (\\mathbf{x}-\\boldsymbol\\mu)^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu) in the density formula is the squared statistical distance of \\mathbf{x} from \\boldsymbol\\mu. It is often referred to as the square of the Mahalanobis distance.\n\n\n\n3.3.1 Some Properties\nIf \\mathbf{x} \\sim N_p(\\boldsymbol\\mu, \\Sigma), then the following statements are true:\n\nMarginal distributions: Each variable is normally distributed, i.e., x_i \\sim N(\\mu_i, \\sigma_{ii}).\nAny linear combinations is normal: Let a_1, \\ldots, a_p \\in \\mathbb{R}. Then \\mathbf{a}^\\top \\mathbf{x} = \\sum_{i=1}^p a_i x_i \\sim N(\\mathbf{a}^\\top \\boldsymbol \\mu, \\mathbf{a}^\\top \\Sigma \\mathbf{a})\nIf \\mathbf{x} \\sim N_p(\\boldsymbol \\mu, \\Sigma), then (\\mathbf{x}-\\boldsymbol\\mu)^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu) \\sim \\chi_p^2\nConditional distributions: Any subset of variables, conditional on others, is normal.\nElliptical contours: The joint density forms ellipses.\n\n\n\n3.3.2 R Exercise: MVN Properties\n\nmu = c(0,0)\nSigma = matrix(c(2,1,1,4),ncol=2, byrow=TRUE)\na = c(1,1)\n\n# simulate from MVN\nset.seed(4750)\nx = MASS::mvrnorm(1, mu=mu, Sigma=Sigma)\n\n\n\nR Code: MVN properties\n# linear combination  \nt(a) %*% x \n\n\n           [,1]\n[1,] -0.4976936\n\n\nR Code: MVN properties\n# quadratic form \nt(x-mu)%*%solve(Sigma)%*%(x-mu)\n\n\n           [,1]\n[1,] 0.07250492",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#visualizing-the-mvn-in-r",
    "href": "ch3/03-MVN.html#visualizing-the-mvn-in-r",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.4 Visualizing the MVN in R",
    "text": "3.4 Visualizing the MVN in R\n\n3.4.1 Visualizing Marginal Distributions\n\n\nR Code: Visualize MVN\nlibrary(MASS) \nset.seed(4750) \nmu &lt;- c(0, 0) \nSigma_none &lt;- matrix(c(1, 0, 0, 1), nrow=2) \nSigma_pos &lt;- matrix(c(1, 0.8, 0.8, 1), nrow=2) \nSigma_neg &lt;- matrix(c(1, -0.8, -0.8, 1), nrow=2)\n\nX_none &lt;- mvrnorm(500, mu, Sigma_none) \nX_pos &lt;- mvrnorm(500, mu, Sigma_pos) \nX_neg &lt;- mvrnorm(500, mu, Sigma_neg)\n\npar(mfrow = c(1,3)) \nplot(X_none, main=\"No Correlation\", xlab=\"X1\", ylab=\"X2\", col=rgb(0,0,1,0.3), pch=16) \nplot(X_pos, main=\"Positive Correlation\", xlab=\"X1\", ylab=\"X2\", col=rgb(0,0.5,0,0.3), pch=16) \nplot(X_neg, main=\"Negative Correlation\", xlab=\"X1\", ylab=\"X2\", col=rgb(1,0,0,0.3), pch=16) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry changing the covariance matrix \\Sigma in the code above.\n\nWhat happens if you set the off-diagonal entries to 0?\nWhat about +0.9 or -0.9?\n\n\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\nLet’s visualize how changing the off-diagonal entries (correlation) in \\Sigma affects the bivariate normal:\n\n\nCode\nlibrary(MASS)\nset.seed(4750)\nmu &lt;- c(0, 0)\n\n# Case 1: No correlation (off-diagonal = 0)\nSigma_none &lt;- matrix(c(1, 0, 0, 1), nrow=2)\nX_none &lt;- mvrnorm(500, mu, Sigma_none)\n\n# Case 2: Strong positive correlation (off-diagonal = +0.9)\nSigma_pos &lt;- matrix(c(1, 0.9, 0.9, 1), nrow=2)\nX_pos &lt;- mvrnorm(500, mu, Sigma_pos)\n\n# Case 3: Strong negative correlation (off-diagonal = -0.9)\nSigma_neg &lt;- matrix(c(1, -0.9, -0.9, 1), nrow=2)\nX_neg &lt;- mvrnorm(500, mu, Sigma_neg)\n\npar(mfrow = c(1,3))\nplot(X_none, main = \"No correlation\", xlab = \"X1\", \n     ylab = \"X2\", col = rgb(0,0,1,0.4), pch = 16)\nplot(X_pos, main = \"Positive correlation\", xlab = \"X1\",\n     ylab = \"X2\", col = rgb(0,0.5,0,0.4), pch = 16)\nplot(X_neg, main = \"Negative correlation\", xlab = \"X1\",\n     ylab = \"X2\", col = rgb(1,0,0,0.4), pch = 16)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Density Contour\n\nA set of all vectors \\mathbf{x} that correspond to a constant height of the density function forms an ellipsoid centered at \\boldsymbol\\mu.\nThe MVN density is constant for all \\mathbf{x}’s that are the same statistical distance from the population mean vector, i.e., all \\mathbf{x}’s that satisfy \n\\sqrt{(\\mathbf{x}-\\boldsymbol\\mu)^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu)} = \\text{constant}.\n\nThe axes of the ellipses are in the directions of the eigenvectors of \\Sigma and the length of the j-th longest axis is proportional to \\sqrt{\\lambda_{j}}, where \\lambda_{j} is the eigenvalue associated with the j-th eigenvector of \\Sigma.\n\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nThe ellipse shows a constant-density contour for the MVN.\nThe red and purple arrows indicate eigenvectors of \\Sigma.\nThe lengths of these arrows are proportional to \\sqrt{\\lambda_j}.\n\n\n\nR Code: Bivariate Normal Density Contour\nlibrary(mvtnorm)\nlibrary(ggplot2)\n\nmu = c(0, 0)\nSigma = matrix(c(1, 0.7, 0.7, 1), 2)\n\n# Create grid\nx = seq(-3, 3, length=100)\ny = seq(-3, 3, length=100)\ngrid = expand.grid(x = x, y = y)\n\n# Compute density at each grid point\ngrid$z = mvtnorm::dmvnorm(as.matrix(grid), \n                           mean = mu, sigma = Sigma)\n\n# Plot contours\nggplot(grid, aes(x = x, y = y, z = z)) +\n  geom_contour_filled(bins = 15) +\n  coord_fixed() +\n  labs(title = \"Bivariate Normal Density (Contours)\",\n       x = \"X1\", y = \"X2\", fill = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 3D Surface Plot\n\n\nR Code: 3D Surface Plot\nlibrary(plotly)\n\nz_matrix &lt;- matrix(grid$z, nrow = length(x), byrow = FALSE)\nplot_ly(x = x, y = y, z = z_matrix) %&gt;%\n  add_surface(\n    contours = list(\n      z = list(show = TRUE, \n               usecolormap = TRUE, \n               highlightcolor = \"#ff0000\", \n               project = list(z = TRUE)))) %&gt;%\n  layout(title = \"Bivariate Normal Density (Surface)\",\n         scene = list(xaxis = list(title = \"X1\"),\n                      yaxis = list(title = \"X2\"),\n                      zaxis = list(title = \"Density\")))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#central-1-alphatimes-100-region-of-mvn",
    "href": "ch3/03-MVN.html#central-1-alphatimes-100-region-of-mvn",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.5 Central (1-\\alpha)\\times 100\\% Region of MVN",
    "text": "3.5 Central (1-\\alpha)\\times 100\\% Region of MVN\n\n3.5.1 Properties of Density Contours\n\n\n\n\n\n\nDefinition\n\n\n\n\nThe probability is 1 - \\alpha that the value of a random vector will be inside the ellipsoid defined by \n(\\mathbf{x}-\\boldsymbol\\mu)^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol\\mu) \\leq \\chi^2_{(p), 1-\\alpha}\n where \\chi^2_{(p),1-\\alpha} is the upper (100 \\times \\alpha) percentile of a chi-square distribution with p degrees of freedom.\nThis is smallest region that has probability (1-\\alpha) of containing a vector of observations randomly selected from the population.\nThe jth axis of this ellipsoid is determined by the eigenvector associated with the j-th largest eigenvalue of \\Sigma, for j = 1,...,p.\nThe distance along the j-th axis from the center to the boundary of the ellipsoid is \\sqrt{\\lambda_j}  \\left( \\frac{2}{p \\Gamma(p/2)} \\right)^{1/p} \\sqrt{ \\chi^2_{(p), 1-\\alpha}}\n\n\n\n\n\n3.5.2 Geometric Properties\n\nThe ratio of the lengths of the major and minor axes is  \\frac{\\text{Length of major axis}}{\\text{Length of minor axis}}=\\frac{\\sqrt{\\lambda_1}}{\\sqrt{\\lambda_2}} \nThe area of the ellipse containing the central (1-\\alpha) \\times 100 \\% of a bivariate normal population is \narea = \\pi \\chi^2_{(2), 1-\\alpha} \\sqrt{\\lambda_1} \\sqrt{\\lambda_2} =\\pi \\chi^2_{(2),1-\\alpha} |\\Sigma|^{1/2} \nFor p-dimensional normal distributions the hypervolume of the p-dimensional ellipsoid is \\frac{2\\pi^{p/2}}{p \\Gamma(p/2)} \\left[\\chi^2_{(p),1-\\alpha}\\right]^{p/2} |\\Sigma|^{1/2} \n\n\n\n\n\n\n\nGamma function\n\n\n\n\n\n\n\\Gamma(1) is defined to be 1.0,\n \\Gamma\\left(\\frac{p}{2}\\right)=\\left(\\frac{p}{2}-1\\right)\\left(\\frac{p}{2}-2\\right) \\cdots (2)(1) when p is an even integer,\nand  \\Gamma(\\frac{p}{2})=\\frac{(p-2)(p-4) \\cdots(3)(1)}{ 2^{(p-1)/2}} \\sqrt{\\pi}  when p is an odd integer\n\n\n\n\n\n\n3.5.3 50% and 90% Contours for Two Bivariate Normals\n\n\nR Code: Bivariate Normal Contours\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(mvtnorm)\n\n# Two bivariate normals: different means, same covariance\nmu1 &lt;- c(0, 0)\nmu2 &lt;- c(2, 2)\nSigma &lt;- matrix(c(2, 1.2, 1.2, 2), 2)\n\n# Grid for density evaluation\nx &lt;- seq(-3, 6, length=120)\ny &lt;- seq(-3, 6, length=120)\ngrid &lt;- expand.grid(x=x, y=y)\nxy = as.matrix(grid)\nz1 &lt;- dmvnorm(xy, mean=mu1, sigma=Sigma)\nz2 &lt;- dmvnorm(xy, mean=mu2, sigma=Sigma)\ngrid$z1 = z1 \ngrid$z2 = z2\n\n# Find contour levels for 50% and 90%\nget_density_level &lt;- function(mu, Sigma, p) {\n  d2 &lt;- qchisq(p, df=2)\n  detS &lt;- det(Sigma)\n  norm_const &lt;- 1/(2*pi*sqrt(detS))\n  exp_part &lt;- exp(-0.5 * d2)\n  norm_const * exp_part\n}\nlevel_50 &lt;- get_density_level(mu1, Sigma, 0.5)\nlevel_90 &lt;- get_density_level(mu1, Sigma, 0.9)\n\n# Plot\nggplot() +\n  geom_contour(data=grid, aes(x=x, y=y, z=z1), \n               breaks=c(level_50, level_90),\n               color=\"blue\", size=1.2, linetype=\"solid\") +\n  geom_contour(data=grid, aes(x=x, y=y, z=z2), \n               breaks=c(level_50, level_90),\n               color=\"red\", size=1.2, linetype=\"dashed\") +\n  geom_point(aes(x=mu1[1], y=mu1[2]), color=\"blue\", size=3) +\n  geom_point(aes(x=mu2[1], y=mu2[2]), color=\"red\", size=3) +\n  annotate(\"text\", x=mu1[1], y=mu1[2]-0.5, \n           label=\"mu1\", color=\"blue\") +\n  annotate(\"text\", x=mu2[1], y=mu2[2]+0.5, \n           label=\"mu2\", color=\"red\") +\n  coord_fixed() +\n  labs(\n    title=\"50% (inner) and 90% (outer) Contours of Two Bivariate Normals\",\n    x=\"X1\", y=\"X2\", \n    caption=\"Density peaks at the mean for each distribution.\") +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#overall-measures-of-variability",
    "href": "ch3/03-MVN.html#overall-measures-of-variability",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.6 Overall Measures of Variability",
    "text": "3.6 Overall Measures of Variability\n\n\n\n\n\n\nMeasures of variability\n\n\n\n\nGeneralized variance and generalized standard deviation tell us about the overall “multivariate” spread or “joint variability”—not just variable by variable, but how “big” the whole data cloud is, including dependencies.\nTotal variance tells us the aggregate variance but is “blind” to how variables overlap (i.e., to correlations).\n\n\n\n\n3.6.1 Generalized Variance\n\nDefinition: |\\Sigma|=\\lambda_1\\lambda_2\\cdots\\lambda_p \nThe generalized variance measures the overall spread of the data in all directions at once.\nIf any variable has no variation, or if there’s perfect linear dependence (collinearity), the generalized variance drops to zero (the volume “flattens”).\n\n\n\n3.6.2 Generalized Standard Deviation\n\nDefinition: |\\Sigma|^{1/2}=\\sqrt{\\lambda_1\\lambda_2\\cdots\\lambda_p} \nThe generalized standard deviation is proportional to the volume of the ellipsoid.\n\n\n\n3.6.3 Total Variance\n\nDefinition \n\\begin{aligned}\ntrace(\\Sigma)\\equiv tr(\\Sigma)&:= \\sigma_{11} + \\sigma_{22} + \\cdots + \\sigma_{pp} \\\\\n               &= \\lambda_1+\\lambda_2+\\cdots+\\lambda_p\n\\end{aligned}\n\nThis is the total marginal variability in all directions, but does not account for correlation.\nIn the ellipsoid analogy, it’s the sum of the squared axis lengths (not the “volume”).\n\n\n\n3.6.4 Example: iris Dataset\nThe iris dataset is a classic and widely used dataset in R, commonly employed for statistical analysis, machine learning, and data visualization. It is built into R and can be loaded directly. Let’s compute the overall measures of the dataset.\n\n# Use iris measurements\nX &lt;- iris[, 1:4]\nhead(X)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1          5.1         3.5          1.4         0.2\n2          4.9         3.0          1.4         0.2\n3          4.7         3.2          1.3         0.2\n4          4.6         3.1          1.5         0.2\n5          5.0         3.6          1.4         0.2\n6          5.4         3.9          1.7         0.4\n\n\n\n\nR Code: Covariance\n# compute covariance \nS &lt;- cov(X)\nprint(S)\n\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length    0.6856935  -0.0424340    1.2743154   0.5162707\nSepal.Width    -0.0424340   0.1899794   -0.3296564  -0.1216394\nPetal.Length    1.2743154  -0.3296564    3.1162779   1.2956094\nPetal.Width     0.5162707  -0.1216394    1.2956094   0.5810063\n\n\n\n\nR Code: Spectral Decomposition\neig &lt;- eigen(S)\nlambda &lt;- eig$values\n\n\n\n\nR Code: Overall Measures\n# Generalized variance: product of eigenvalues\ngen_var &lt;- prod(lambda)\n# Generalized standard deviation: sqrt of product\ngen_sd &lt;- sqrt(prod(lambda))\n# Total variance: sum of eigenvalues\ntotal_var &lt;- sum(lambda)\nlibrary(tibble)\nresult = tibble(\n  \"Generalized variance\" = gen_var,\n  \"Generalized standard deviation\" = gen_sd,\n  \"Total variance\" = total_var\n)\nprint(t(result))\n\n\n                                     [,1]\nGeneralized variance           0.00191273\nGeneralized standard deviation 0.04373476\nTotal variance                 4.57295705",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#assessing-normality",
    "href": "ch3/03-MVN.html#assessing-normality",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.7 Assessing Normality",
    "text": "3.7 Assessing Normality\n\nAssessing multivariate normality is difficult.\nIf any single variable does not have a normal distribution, then the joint distribution of p random variables cannot have a normal distribution.\nWe can check normality for each variable individually. If we reject normality for any variable then the joint distribution is not multivariate normal.\nAlso look at scatter plots of pairs of variables.\nLook for outliers.\n\n\n3.7.1 Normal Q-Q plots\n\nA quantile-quantile (Q-Q) plot can also be constructed for each of the p variables.\nIn a Q-Q plot, we plot the ordered data (sample quantiles) against the quantiles that would be expected if the sample came from a standard normal distribution.\nIf the hypothesis of normality holds, the points in the plot will fall closely along a straight line.\n\n\n\n\n\n\n\nNormal Q-Q plots\n\n\n\n\nThe slope of the line passing through the points is an estimate of the population standard deviation.\nThe intercept of the estimated line is an estimate of the population mean.\nThe sample quantiles are just the sample order statistics. For a sample x_1, x_2,...,x_n, quantiles are obtained by ordering sample observations \nx_{(1)} \\leq x_{(2)} \\leq ... \\leq x_{(n)},\n where x_{(j)} is the jth smallest sample observation.\n\n\n\n\n\nR Code: Q-Q Plots\n# Normal Q-Q plots for all variables in iris[, 1:4]\npar(mfrow = c(2,2))\nfor (i in 1:4) {\n  qqnorm(iris[,i], main = colnames(iris)[i])\n  qqline(iris[,i], col = \"blue\", lwd = 2)\n}\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nIf the points follow the line closely, that variable is approximately normal.\nSystematic departures from the line (curves, s-shapes, outliers) suggest non-normality.\n\n\n\nR Code: Scatterplots\n# Also look at scatterplots for pairs of variables\npairs(iris[,1:4], main = \"Scatterplots: Iris Variables\")\n\n\n\n\n\n\n\n\n\nInterpretation: - Outliers, nonlinear patterns, or heavy tails in these scatterplots suggest deviations from the multivariate normal model.\n\n\n3.7.2 Shapiro-Wilk Test\n\nThe Shapiro-Wilk test is a statistical test for normality. If the p-value is small (typically &lt;0.05), we reject the null hypothesis of normality.\nTest statistic: A weighted correlation between the x_{(j)} and the q_{(j)}: \nW = \\left( \\frac{\\sum_{i = 1}^n a_j(x_{(i)} - \\bar{x})(q_{(i)} - \\bar{q}) }{\\sqrt{\\sum_{i = 1}^n a_j^2(x_{(i)} - \\bar{x})^2}\\sqrt{\\sum_{i = 1}^n (q_{(i)} - \\bar{q})^2}}  \\right)^2.\n\nWe expect values of W to be close to one if the sample arises from a normal population.\nReject the null hypothesis that data were sampled from a normal distribution if W is too small.\nThis test has been extended to p-dimensional normal distributions.\n\n\n\n\n\n\n\nShapiro-Wilk Test\n\n\n\nThe Shapiro-Wilk test only checks marginal normality, not joint/multivariate normality when applied to each variable individually. This univariate test is implemented in the R function shapiro.test. To perform multivariate normaltiy check, we need to use the multivariate version of the Shapiro-Wilk test using the function mvShapiro.Test from the package mvShapiroTest.\n\n\n\n\nR Code: Univariate Normality Test\n# Shapiro-Wilk test for each of the four numeric iris variables\napply(iris[, 1:4], 2, shapiro.test)\n\n\n$Sepal.Length\n\n    Shapiro-Wilk normality test\n\ndata:  newX[, i]\nW = 0.97609, p-value = 0.01018\n\n\n$Sepal.Width\n\n    Shapiro-Wilk normality test\n\ndata:  newX[, i]\nW = 0.98492, p-value = 0.1012\n\n\n$Petal.Length\n\n    Shapiro-Wilk normality test\n\ndata:  newX[, i]\nW = 0.87627, p-value = 7.412e-10\n\n\n$Petal.Width\n\n    Shapiro-Wilk normality test\n\ndata:  newX[, i]\nW = 0.90183, p-value = 1.68e-08\n\n\n\n\nR Code: Multivariate Normality Test\nlibrary(mvShapiroTest)\n# multivariate Shapiro-Wilk test \nmvShapiro.Test(as.matrix(iris[, 1:4]))\n\n\n\n    Generalized Shapiro-Wilk test for Multivariate Normality by\n    Villasenor-Alva and Gonzalez-Estrada\n\ndata:  as.matrix(iris[, 1:4])\nMVW = 0.97327, p-value = 1.655e-06\n\n\n\n\n\n\n\n\nExercise: Assessing Normality with Real Data (mtcars)\n\n\n\nUsing the mtcars dataset, explore the relationship between mpg (miles per gallon) and hp (horsepower):\n\nMake a scatterplot of mpg vs hp and describe the pattern.\nOverlay bivariate normal contours (fit the mean and covariance from the data).\nDraw normal Q-Q plots for mpg and hp.\nPerform the Shapiro-Wilk test for both variables.\nInterpret your results: Does either variable appear to be normally distributed? Does the joint distribution appear approximately elliptical (as would be expected under bivariate normality)?\n\n\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nR Code: View Solution\nlibrary(mvtnorm)\nlibrary(ggplot2)\n\ndata(mtcars)\nX &lt;- mtcars[, c(\"mpg\", \"hp\")]\nmu &lt;- colMeans(X)\nSigma &lt;- cov(X)\n\n\np &lt;- ggplot(X, aes(x = mpg, y = hp)) +\n  geom_point(size = 2, alpha = 0.7) +\n  theme_minimal() +\n  labs(title = \"mtcars: mpg vs hp\")\n\nx_seq &lt;- seq(min(X$mpg) - 2, max(X$mpg) + 2, length = 100)\ny_seq &lt;- seq(min(X$hp) - 10, max(X$hp) + 10, length = 100)\ngrid &lt;- expand.grid(mpg = x_seq, hp = y_seq)\ngrid$z &lt;- dmvnorm(as.matrix(grid), mean = mu, sigma = Sigma)\n\nget_density_level &lt;- function(Sigma, p) {\n  d2 &lt;- qchisq(p, df=2)\n  detS &lt;- det(Sigma)\n  norm_const &lt;- 1/(2*pi*sqrt(detS))\n  exp_part &lt;- exp(-0.5 * d2)\n  norm_const * exp_part\n}\nlevel_50 &lt;- get_density_level(Sigma, 0.5)\nlevel_90 &lt;- get_density_level(Sigma, 0.9)\n\np + \n  geom_contour(data = grid, aes(z = z), breaks = level_50, \n               color = \"blue\", linetype = \"solid\", size = 1.2) +\n  geom_contour(data = grid, aes(z = z), breaks = level_90, \n               color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(subtitle = \"Blue: 50% contour | Red dashed: 90% contour\")\n\n\n\n\n\n\n\n\n\nR Code: View Solution\npar(mfrow = c(1,2))\nqqnorm(X$mpg, main = \"Normal Q-Q: mpg\"); qqline(X$mpg, col = \"blue\")\nqqnorm(X$hp, main = \"Normal Q-Q: hp\"); qqline(X$hp, col = \"blue\")\n\n\n\n\n\n\n\n\n\nR Code: View Solution\npar(mfrow = c(1,1))\n\nsw1 &lt;- shapiro.test(X$mpg)\nsw2 &lt;- shapiro.test(X$hp)\ncat(\"Shapiro-Wilk p-value for mpg:\", signif(sw1$p.value, 3), \"\\n\")\n\n\nShapiro-Wilk p-value for mpg: 0.123 \n\n\nR Code: View Solution\ncat(\"Shapiro-Wilk p-value for hp:\", signif(sw2$p.value, 3), \"\\n\")\n\n\nShapiro-Wilk p-value for hp: 0.0488 \n\n\nR Code: View Solution\n# 5. multivariate Shapiro-Wilk test\nmvShapiro.Test(as.matrix(X[, c(\"mpg\", \"hp\")]))\n\n\n\n    Generalized Shapiro-Wilk test for Multivariate Normality by\n    Villasenor-Alva and Gonzalez-Estrada\n\ndata:  as.matrix(X[, c(\"mpg\", \"hp\")])\nMVW = 0.92425, p-value = 0.00639\n\n\nInterpretation:\n\nThe scatterplot shows the relationship between mpg and hp (likely negative).\nThe bivariate normal contours (fit from the data) show the estimated “ellipse” of the joint distribution.\nQ-Q plots help check whether each variable is approximately normal (look for straightness).\nShapiro-Wilk p-values: p &lt; 0.05 indicates non-normality; p &gt; 0.05 suggests no evidence against normality.\nIf either variable is non-normal or the scatterplot is strongly non-elliptical (e.g., curved, outliers), the joint distribution is not truly bivariate normal.\n\n\n\n\n\n\n3.7.3 Transformations to Near Normality\nIf observations show gross departures from normality, it might be necessary to transform some of the variables to near normality. Some recommendations are given below.\n\n\n\n\n\n\n\nOriginal scale\nTransformed scale\n\n\n\n\nRight skewed data\n\\sqrt{x}   log(x)   1/\\sqrt{x}   1/x\n\n\nx are counts\n\\sqrt{x}\n\n\nx are proportions \\hat{p}\n\\mathrm{logit}(\\hat{p}) = \\frac{1}{2} \\log\\left(\\frac{\\hat{p}}{1 - \\hat{p}}\\right)\n\n\nx are correlations r\nFisher’s z(r) = \\frac{1}{2} \\log\\left(\\frac{1 + r}{1 - r}\\right)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#detecting-outliers",
    "href": "ch3/03-MVN.html#detecting-outliers",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.8 Detecting Outliers",
    "text": "3.8 Detecting Outliers\n\nAn outlier is a measurement that appears to be much different from neighboring observations.\nIn the univariate case with adequate sample sizes, and assuming that normality holds, an outlier can be detected by:\n\nStandardizing the n measurements so that they are approximately N(0, \\ 1)\nFlagging observations with standardized values below or above 3.5 or thereabouts.\n\nIn p dimensions, detecting outliers is not so easy. A sample unit which may not appear to be an outlier in each of the marginal distributions can still be an outlier relative to the multivariate distribution.\n\n\n3.8.1 Steps for Detecting Outliers\n\nInvestigate all univariate marginal distributions by computing the standardized values z_{ji} = (x_{ji} - \\bar{x}_i) / \\sqrt{\\sigma_{ii}} for the j-th sample unit and the i-th variable.\nIf p is moderate, construct all bivariate scatter plots. There are p(p-1)/2 of them.\nFor each sample unit, calculate the squared distance d^2_j = (\\mathbf{x}_j - \\bar{\\mathbf{x}})'S^{-1}(\\mathbf{x}_j - \\bar{\\mathbf{x}}), where \\mathbf{x}_j is the p \\times 1 vector of measurements on the j-th sample unit.\nTo decide if d^2_j is extreme, recall that the d^2_j are approximately \\chi^2_p. For example, if n = 100, we would expect to observe about 5 squared distances larger than the 0.95 percentile of the \\chi^2_p distribution.\n\n\n\n3.8.2 Example: iris Data\n\n\nVisualizing Data Using Scatterplot and Marginal Dot Plots\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndf = iris\n# Bin along x\nx_proj &lt;- df %&gt;%\n  dplyr::mutate(y = 2)\n\n# Bin along y\ny_proj &lt;- df %&gt;%\n  mutate(x = 4)\n\nggplot(df, \n  aes(x = Sepal.Length, \n      y = Sepal.Width, color = Species)) +\n  geom_point(size = 1, alpha = 0.7) +\n  geom_dotplot(data = x_proj, \n               aes(x = Sepal.Length, y=2, fill = Species),\n               binaxis = \"x\", stackdir = \"down\", dotsize = 0.5,\n               position = position_nudge(y=1.5),\n               inherit.aes = FALSE) +\n  geom_dotplot(data = y_proj, \n               aes(x=3.5, y = Sepal.Width, fill = Species),\n               binaxis = \"y\", stackdir = \"down\", dotsize = 0.5,\n               position = position_nudge(x=0),\n               inherit.aes = FALSE) +\n  coord_equal() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nDetecting Outliers Using Mahalanobis Distances\n## Finding mahalanobis distance\nxbar = colMeans(df[, 1:4])\nbvar = cov(df[,1:4])\ndsq = mahalanobis(x=df[,1:4], center=xbar, cov=bvar)\n\n## Cutoff value for distances from a chisquare distribution\ncutoff = qchisq(p=0.95, df=nrow(bvar)) # 95th percentile \n\n## plot observations whose distance is greater than cutoff value\nflag = dsq&gt;cutoff\ncbind(df[flag,1:4], d_sqaure=dsq[flag])\n\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width  d_sqaure\n16           5.7         4.4          1.5         0.4  9.712790\n42           4.5         2.3          1.3         0.3 11.424029\n107          4.9         2.5          4.5         1.7 10.137804\n115          5.8         2.8          5.1         2.4 11.410573\n118          7.7         3.8          6.7         2.2 12.813073\n132          7.9         3.8          6.4         2.0 13.101093\n135          6.1         2.6          5.6         1.4 12.880331\n136          7.7         3.0          6.1         2.3  9.656936\n142          6.9         3.1          5.1         2.3 12.441384\n\n\n\n\nScatterplot and Dot Plot\n# Add flag for outliers\ndf = df %&gt;%\n  mutate(flag = dsq &gt; cutoff)\n\n# Projections\nx_proj = df %&gt;% mutate(y = 2)\ny_proj = df %&gt;% mutate(x = 4)\n\nggplot(df, aes(x = Sepal.Length, y = Sepal.Width)) +\n  # Scatter plot with flagged points highlighted\n  geom_point(aes(color = Species,\n                 shape = flag,    # Different shape for flagged\n                 size = ifelse(flag, 3, 1.5)), # Larger for flagged\n             alpha = 0.7) +\n  # X-axis projection\n  geom_dotplot(\n    data = x_proj,\n    aes(x = Sepal.Length, y = 2, fill = Species),\n    binaxis = \"x\", stackdir = \"down\", binwidth = 0.15, \n    dotsize = 0.5,\n    position = position_nudge(y = 1.5),\n    inherit.aes = FALSE\n  ) +\n  # Y-axis projection\n  geom_dotplot(\n    data = y_proj,\n    aes(x = 3.5, y = Sepal.Width, fill = Species),\n    binaxis = \"y\", stackdir = \"down\", binwidth = 0.15, \n    dotsize = 0.5,\n    position = position_nudge(x = 0),\n    inherit.aes = FALSE\n  ) +\n  scale_shape_manual(\n    values = c(\n      `FALSE` = 16, \n      `TRUE` = 21)) + # open circle for outliers\n  scale_size_identity() +\n  coord_equal() +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch3/03-MVN.html#exercises",
    "href": "ch3/03-MVN.html#exercises",
    "title": "3  Multivariate Normal Distribution",
    "section": "3.9 Exercises",
    "text": "3.9 Exercises\n\n3.9.1 Exercise 1: Perspiration Data\nThese data were taken from an example in the Johnson and Wichern book, Applied Multivariate Analysis in the file sweat.dat. Three measurements on perspiration were taken from each woman in a random sample of 20 healthy women: X_1= sweat rate, X_2= sodium concentration, X_3=potassium concentration.\n\nRead the data into R.\nCompute the sample mean and sample covariance\nTreat sample mean and sample covariance as the estimate of population parameters and evaluate the MVN pdf for a range of possible values of variables X_1, X_2.\nCompute the mean and variance of 0.5X_1+ 0.5 X_2 and X_1-X_2.\nPlot the bivariate normal density contour for X_1, X_2 using sample mean and sample covariance.\nPlot a scatterplot with points outside the 95% highlighted.\nCompute Ellipse axes via spectral decomposition.\nCompute generalized variance and total variance based on the whole dataset.\n\nPerform normality check for all the variables.\nDetect any possible outliers at level \\alpha =0.05 for all the variables.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\ndat = read.table(\"sweat.dat\", header=F, \n                 col.names=c(\"subject\", \"x1\", \"x2\", \"x3\") )\nhead(dat)\n\n\n  subject  x1   x2   x3\n1       1 3.7 48.5  9.3\n2       2 5.7 65.1  8.0\n3       3 3.8 47.2 10.9\n4       4 3.2 53.2 12.0\n5       5 3.1 55.5  9.7\n6       6 4.6 36.1  7.9\n\n\nCode\nX = as.matrix(dat[,c(2,3)])\n\n\n\n\nCode\nxbar = colMeans(X)\nS = cov(X)\nS\n\n\n          x1       x2\nx1  2.879368  10.0100\nx2 10.010000 199.7884\n\n\n\n\nCode\ngrid &lt;- expand.grid(\n  x = seq(min(X[,1]) - 0.5, max(X[,1]) + 0.5, length = 50),\n  y = seq(min(X[,2]) - 0.5, max(X[,2]) + 0.5, length = 50)\n)\ngridmat = as.matrix(grid)\ndens &lt;- mvtnorm::dmvnorm(x=gridmat, \n                         mean = xbar, \n                         sigma = S)\nhead(data.frame(grid, f = dens))\n\n\n         x  y            f\n1 1.000000 13 0.0002244281\n2 1.163265 13 0.0002563175\n3 1.326531 13 0.0002894749\n4 1.489796 13 0.0003232772\n5 1.653061 13 0.0003570021\n6 1.816327 13 0.0003898505\n\n\n\n\nCode\n# mean, var\na1 = c(0.5, 0.5)\na2 = c(1, -1)\n\n# mean and variance of 0.5*X1 + 0.5*X2\ntibble(\n  mean = sum(a1 * xbar),\n  variance = drop(t(a1) %*% solve(S) %*% a1)\n)\n\n\n# A tibble: 1 × 2\n   mean variance\n  &lt;dbl&gt;    &lt;dbl&gt;\n1  25.0   0.0961\n\n\nCode\n# mean and variance of X1 - X2\ntibble(\n  mean = sum(a2 * xbar),\n  variance = drop(t(a2) %*% solve(S) %*% a2)\n)\n\n\n# A tibble: 1 × 2\n   mean variance\n  &lt;dbl&gt;    &lt;dbl&gt;\n1 -40.8    0.469\n\n\n\n\nCode\ngrid$z = dens \nggplot(grid, aes(x = x, y = y, z = z)) +\n  geom_contour_filled(bins = 10) +\n  #coord_equal() +\n  labs(title = \"Bivariate Normal Density (Contours)\",\n       x = \"Sweat rate\", y = \"Sodium concentration\", \n       fill = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nXc = X - matrix(1, nrow=nrow(X), ncol=1) %*% t(xbar)\nQ = diag( Xc %*% solve(S) %*% t(Xc) )\n# or use T2 = rowSums( (Xc %*% solve(S)) * Xc)\ncut = qchisq(.95, df=2)\nmean(Q&lt;=cut) # empirical coverage \n\n\n[1] 0.95\n\n\nCode\ndat1 = as.data.frame(X) %&gt;% \n  mutate(inside = Q&lt;=cut)\nggplot(dat1, aes(x=x1, y=x2, color=inside)) + \n  geom_point(size=2, alpha=.8) + \n  scale_color_manual(values = c(\"FALSE\"=\"grey60\",\n                                \"TRUE\"=\"tomato\")) + \n  labs(color = \"Inside 95% ellipse?\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nE = eigen(S)\n\n# Ellipse directions\nE$vectors\n\n\n          [,1]       [,2]\n[1,] 0.0506399 -0.9987170\n[2,] 0.9987170  0.0506399\n\n\nCode\n# lengths\nsqrt(E$values) * sqrt(cut)\n\n\n[1] 34.641972  3.769698\n\n\n\n\nCode\ntibble(\n  \"Generalized variance\" = prod(E$values),\n  \"Total variance\" = sum(E$values)\n)\n\n\n# A tibble: 1 × 2\n  `Generalized variance` `Total variance`\n                   &lt;dbl&gt;            &lt;dbl&gt;\n1                   475.             203.\n\n\n\n\nCode\npar(mfrow = c(1,3))\nfor (nm in colnames(dat[,2:4])) {\n  qqnorm(dat[, nm], main = paste(\"QQ:\", nm))\n  qqline(dat[, nm])\n}\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(1,1))\n\napply(dat[, 2:4], 2, function(v) shapiro.test(v)$p.value)\n\n\n       x1        x2        x3 \n0.8689242 0.9861883 0.6232620 \n\n\nCode\nmvShapiroTest::mvShapiro.Test(as.matrix(dat[,2:4]))\n\n\n\n    Generalized Shapiro-Wilk test for Multivariate Normality by\n    Villasenor-Alva and Gonzalez-Estrada\n\ndata:  as.matrix(dat[, 2:4])\nMVW = 0.94446, p-value = 0.2567\n\n\n\n\nCode\ndat1 = as.matrix(dat[,2:4])\nxbar1 = colMeans(dat1)\nS1 = cov(dat1)\nXc1 = dat1 - matrix(1,nrow(dat1), 1) %*% t(xbar1)\nd2 = diag( (Xc1) %*% solve(S1) %*% t(Xc1) )\n\ncut2 = qchisq(.975, df=ncol(dat1))\nsum(d2&gt;cut2)\n\n\n[1] 0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multivariate Normal Distribution</span>"
    ]
  },
  {
    "objectID": "ch2/02-graphs.html",
    "href": "ch2/02-graphs.html",
    "title": "2  Graphs and Data Visualization",
    "section": "",
    "text": "2.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Graphs and Data Visualization</span>"
    ]
  },
  {
    "objectID": "ch1/01-intro.html",
    "href": "ch1/01-intro.html",
    "title": "1  Introduction to Multivariate Data",
    "section": "",
    "text": "1.1 Course Outline",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Multivariate Data</span>"
    ]
  }
]