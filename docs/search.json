[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Multivariate Data Analysis",
    "section": "",
    "text": "Preface\nThis book contains the course notes for STAT 4750/5750 (Introduction to Multivariate Data Analysis) at Iowa State University. This course is designed for undergraduate students in statistics and data science and graduate students from the applied sciences with majors outside statistics. The prerequisite for this course includes STAT 3010 or STAT 3260 (for undergraduates) or STAT 5101 for graduate students. Knowledge of matrix algebra is recommended but not required to understand the topics covered in this book.\nThe course STAT 3010 (Intermediate Statistical Concepts and Methods) covers statistical concepts and methods used in the analysis of observational data. Topics include analysis of single sample, two sample and paired sample data; simple and multiple linear regression; model building and analysis of residuals; one-way ANOVA, tests of independence for contingency tables, and logistic regression.\nThe course STAT 3260 (Introduction to Business Statistics II) covers multiple regression, regression diagnostics, model building, applications in analysis of variance and time series, random variables, conditional probability, and data visualization.\nThe course STAT 5101 (Statistical Methods for Research Workers) was renamed from the previous course STAT 5870 starting Fall 2025. STAT 5101 is a first course in statistics for graduate students from the applied sciences, and covers topics including basic experimental designs and analysis of variance, analysis of categorical data, logistic and log-linear regression, likelihood-based inference, and the use of simulation.\nStudents who have the needed backgrounds shall find the statistical concepts and methods in this book easy to follow and understand. All the methods are illustrated with various examples with step-by-step solutions and extensive R code. Exercises are also given at each chapter to help students better understand the statistical methods and apply these methods for real data analysis by adapting the corresponding R code in the book.\nThe materials in this book are largely influenced by previous course notes taught by several instructors including Yumou Qiu and Kenneth Koehler in the Department of Statistics at Iowa State University."
  },
  {
    "objectID": "ch1/01-intro.html#course-outline",
    "href": "ch1/01-intro.html#course-outline",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.1 Course Outline",
    "text": "1.1 Course Outline\n\nIntroduction to Multivariate Data\nNumerical Summaries and Visualization of Multivariate Data\nMultivariate Normal Distribution\nComparing Centers of Distributions\n(Hotelling T^2, MANOVA, Repeated Measures)\nPrincipal Component Analysis\n(Summarizing data in lower dimensions)\nExploratory Factor Analysis\n(What to do when the variables of interest cannot be directly observed.)\nMulti-Dimensional Scaling\nCluster Analysis\nDiscriminant Analysis and Classification\n(Including linear discriminants, logistic regression, classification trees, and random forests)"
  },
  {
    "objectID": "ch1/01-intro.html#objectives-of-multivariate-analysis",
    "href": "ch1/01-intro.html#objectives-of-multivariate-analysis",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.2 Objectives of Multivariate Analysis",
    "text": "1.2 Objectives of Multivariate Analysis\n\nUnderstand dependencies among variables: What is the nature of associations among variables?\nPrediction: If variables are associated, then we might be able to predict the value of some of them given information on the others. (Statistical inference)\nHypothesis testing: Are differences in sets of response means for two or more groups large enough to be distinguished from sampling variation? (Statistical inference)\nDimensionality reduction: Can we reduce the dimensionality of the problem by considering a small number of (linear) combinations of a large number of measurements without losing important information?\n\nPrincipal Components\nFactor Analysis\nMultidimensional Scaling\n\nGrouping (Cluster Analysis): Identify groups of “similar” units using a common set of measured traits.\nClassification: Classify units into previously defined groups using a common set of measured traits."
  },
  {
    "objectID": "ch1/01-intro.html#introduction-to-r-and-rstudio",
    "href": "ch1/01-intro.html#introduction-to-r-and-rstudio",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.3 Introduction to R and RStudio",
    "text": "1.3 Introduction to R and RStudio\n\n1.3.1 Getting Started\nTo download R, please choose your preferred CRAN mirror. Here I recommend the mirror 0-Cloud available at https://cloud.r-project.org/.\nInstall R on macOS\nFor macOS users, below are the steps you need to install R.\n\nInstall Xcode (e.g., via the App Store). Skip this step if your Mac already has Xcode installed.\nInstall XQuartz.\nGo to https://cloud.r-project.org/ and click “Download R for macOS.”\nClick on the download link for the latest R version for macOS and follow the instruction.\n\nInstall R on Windows:\nFor Windows users, the following instructions guide you to install R.\n\nGo to https://cloud.r-project.org/ and click “Download R for Windows.”\nClick “install R for the first time.”\nChoose a download mirror (any CRAN mirror will work).\nClick on the download link for the latest R version for Windows and follow the instruction\n\nInstall RStudio\nRStudio has multiple panes in the window, open by default: one for writing and editing code, another for executing it, another for plots produced or help, and another that lists the R data objects available. RStudio can be download for free at https://posit.co/download/rstudio-desktop/.\n\n\n1.3.2 Introduction to R Programming\n\n\n\n\n\n\nSome Tips: R Working Environment\n\n\n\n\n\nWhenever you work with R for data analysis, it is recommended to load all the packages used in the data analysis pipeline before the function sessionInfo(). In addition, if random numbers are generated, it is also recommended to set random seed to ensure reproducibility using set.seed().\n\n\nR Working Environment\n# load packages \nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(lubridate)\n\nsessionInfo()\n\n\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.7.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lubridate_1.9.4 readr_2.1.5     tidyr_1.3.1     dplyr_1.1.4    \n[5] ggplot2_3.5.2  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       cli_3.6.3         knitr_1.49        rlang_1.1.5      \n [5] xfun_0.50         purrr_1.0.2       generics_0.1.3    jsonlite_1.8.9   \n [9] glue_1.8.0        colorspace_2.1-1  htmltools_0.5.8.1 hms_1.1.3        \n[13] scales_1.3.0      rmarkdown_2.29    grid_4.4.3        evaluate_1.0.3   \n[17] munsell_0.5.1     tibble_3.2.1      tzdb_0.4.0        fastmap_1.2.0    \n[21] yaml_2.3.10       lifecycle_1.0.4   compiler_4.4.3    timechange_0.3.0 \n[25] htmlwidgets_1.6.4 pkgconfig_2.0.3   rstudioapi_0.17.1 digest_0.6.37    \n[29] R6_2.5.1          tidyselect_1.2.1  pillar_1.10.1     magrittr_2.0.3   \n[33] withr_3.0.2       tools_4.4.3       gtable_0.3.6     \n\n\n\n\n\n\n\n\n\n\n\nR is a Calculator\n\n\n\n\n\n\nCode\n# Numeric, logical, character types\n3.14159             # numeric\n\n[1] 3.14159\n\nCode\nT                   # logical, can also be TRUE\n\n[1] TRUE\n\nCode\nF                   # logical, can also be FALSE \n\n[1] FALSE\n\nCode\n\"Stat 4750/5750\"    # character\n\n[1] “Stat 4750/5750”\n\nCode\n# Basic arithmetic operators\n1 + 2\n\n[1] 3\n\nCode\n20 - 3\n\n[1] 17\n\nCode\n2 * 6\n\n[1] 12\n\nCode\n4 / 3\n\n[1] 1.333333\n\nCode\n2 ^ 4\n\n[1] 16\n\nCode\n-3.14\n\n[1] -3.14\n\nCode\n(1 + 2) * (3 / 4)  # use parenthesis\n\n[1] 2.25\n\nCode\n2 == 1\n\n[1] FALSE\n\nCode\n# Vector\nc()  # empty vector\n\nNULL\n\nCode\nc(1, 2, 3, 4)\n\n[1] 1 2 3 4\n\nCode\n1:4\n\n[1] 1 2 3 4\n\nCode\n# Look up the function help, 3 ways:\n# Following 3 ways work for most functions\n          # 1. search in help pane\n?sum      # 2. use ?\nsum(1:4)  # 3. move your cursor to the function, then press F1, the easiest way\n\n[1] 10\n\nCode\n# The 3rd way doesn't work for functions having some symbols, like +, ==, %*%\n          # 1. search in help pane\n?`+`      # 2. use ? but wrap the symbol with ``\n\n\n\n\n\n\n\n\n\n\nR Objects\n\n\n\n\n\n\n\nCode\n# Assignment operator &lt;-\n\n# Numeric class\nmynumbers &lt;- 5:12\nmynumbers\n\n\n[1]  5  6  7  8  9 10 11 12\n\n\nCode\nmynumbers + 2\n\n\n[1]  7  8  9 10 11 12 13 14\n\n\nCode\nmynumbers * 10\n\n\n[1]  50  60  70  80  90 100 110 120\n\n\nCode\ntypeof(mynumbers)      # type of an object\n\n\n[1] \"integer\"\n\n\nCode\n# check if is numeric (both integer and double type are numeric)\nis.numeric(mynumbers)  \n\n\n[1] TRUE\n\n\nCode\nis.vector(mynumbers)   # check if is vector\n\n\n[1] TRUE\n\n\nCode\nlength(mynumbers)      # length of an object\n\n\n[1] 8\n\n\nCode\n# Character class\nmytext &lt;- c(\"hello\", \"class\", \"four\") \nmytext\n\n\n[1] \"hello\" \"class\" \"four\" \n\n\nCode\ntypeof(mytext)\n\n\n[1] \"character\"\n\n\nCode\nis.numeric(mytext)\n\n\n[1] FALSE\n\n\nCode\nis.character(mytext)\n\n\n[1] TRUE\n\n\nCode\nis.character(mynumbers)\n\n\n[1] FALSE\n\n\nCode\nis.vector(mytext)\n\n\n[1] TRUE\n\n\nCode\nlength(mytext)\n\n\n[1] 3\n\n\nCode\n# Logical class\nmylogic &lt;- c(TRUE, FALSE, TRUE, TRUE)\ntypeof(mylogic)\n\n\n[1] \"logical\"\n\n\nCode\n# Factor class\ngender &lt;- c(\"male\", \"female\", \"female\", \"female\", \"male\") \ngender\n\n\n[1] \"male\"   \"female\" \"female\" \"female\" \"male\"  \n\n\nCode\nis.vector(gender)\n\n\n[1] TRUE\n\n\nCode\nis.character(gender)\n\n\n[1] TRUE\n\n\nCode\nis.vector(gender)\n\n\n[1] TRUE\n\n\nCode\nis.factor(gender)\n\n\n[1] FALSE\n\n\nCode\ngenderf &lt;- factor(gender)\ngenderf\n\n\n[1] male   female female female male  \nLevels: female male\n\n\nCode\nis.character(genderf)\n\n\n[1] FALSE\n\n\nCode\nis.factor(genderf)\n\n\n[1] TRUE\n\n\nCode\nsummary(mynumbers)  # numeric: 5-number summary\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00    6.75    8.50    8.50   10.25   12.00 \n\n\nCode\nsummary(mylogic)    # logical: count how many T and F\n\n\n   Mode   FALSE    TRUE \nlogical       1       3 \n\n\nCode\nsummary(mytext)     # character:\n\n\n   Length     Class      Mode \n        3 character character \n\n\nCode\nsummary(genderf)    # factor: count the frequency\n\n\nfemale   male \n     3      2 \n\n\nCode\n# List class\nmylist &lt;- list(1, \"ABC\", FALSE)\nmylist\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"ABC\"\n\n[[3]]\n[1] FALSE\n\n\nCode\nis.vector(mylist)\n\n\n[1] TRUE\n\n\nCode\nis.list(mylist)\n\n\n[1] TRUE\n\n\nCode\nlength(mylist)\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\n\n\nWorking with Matrices\n\n\n\n\n\n\n\nCode\n# All elements should be the same type\nmydata &lt;- matrix(c(140, 120, 160, 145, 125, 65, 60, 63, 66, 61), ncol = 2, byrow = FALSE) \nmydata\n\n\n     [,1] [,2]\n[1,]  140   65\n[2,]  120   60\n[3,]  160   63\n[4,]  145   66\n[5,]  125   61\n\n\nCode\ndim(mydata)  # dimensions\n\n\n[1] 5 2\n\n\nCode\ncolnames(mydata) &lt;- c(\"Weight.lbs\", \"Height.in\")\nrownames(mydata) &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nmydata\n\n\n  Weight.lbs Height.in\na        140        65\nb        120        60\nc        160        63\nd        145        66\ne        125        61\n\n\nCode\nsummary(mydata)  # summary of each column\n\n\n   Weight.lbs    Height.in \n Min.   :120   Min.   :60  \n 1st Qu.:125   1st Qu.:61  \n Median :140   Median :63  \n Mean   :138   Mean   :63  \n 3rd Qu.:145   3rd Qu.:65  \n Max.   :160   Max.   :66  \n\n\n\n\n\n\n\n\n\n\n\nWorking with Data Frames\n\n\n\n\n\n\n\nData Frames\n# Different columns can have different types\ndf &lt;- data.frame(Weight.lbs = c(140, 120, 160, 145, 125, 180, 165),\n                 Height.in = c(65, 60, 63, 66, 61, 70, 68),\n                 Gender = c(rep(\"Female\", 5), rep(\"Male\", 2)), stringsAsFactors = T)\ndf\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n7        165        68   Male\n\n\nData Frames\ndim(df)\n\n\n[1] 7 3\n\n\nData Frames\nhead(df)     # the first 6 rows\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n\n\nData Frames\nsummary(df)  # summary of each column\n\n\n   Weight.lbs      Height.in        Gender \n Min.   :120.0   Min.   :60.00   Female:5  \n 1st Qu.:132.5   1st Qu.:62.00   Male  :2  \n Median :145.0   Median :65.00             \n Mean   :147.9   Mean   :64.71             \n 3rd Qu.:162.5   3rd Qu.:67.00             \n Max.   :180.0   Max.   :70.00             \n\n\nData Frames\nstr(df)      # structure of the data frame\n\n\n'data.frame':   7 obs. of  3 variables:\n $ Weight.lbs: num  140 120 160 145 125 180 165\n $ Height.in : num  65 60 63 66 61 70 68\n $ Gender    : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 2\n\n\na tibble is a modern implementation of a data frame, designed to be more user-friendly and efficient, especially when working with large datasets.\n\n\ntibble\n# install.packages(\"tibble\")\nlibrary(tibble)\n# create a tibble from an existing object\nas_tibble(df) \n\n\n# A tibble: 7 × 3\n  Weight.lbs Height.in Gender\n       &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; \n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70 Male  \n7        165        68 Male  \n\n\ntibble\n# create a new tibble \ntibble(x=1:5, \n       y=1.0,\n       z=x^2+y)\n\n\n# A tibble: 5 × 3\n      x     y     z\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     2\n2     2     1     5\n3     3     1    10\n4     4     1    17\n5     5     1    26\n\n\ntibble\n# define a row-by-row tibble\ntribble(\n  ~x, ~y, ~z,\n  \"a\", 2, 1,\n  \"b\", 3, 4\n)\n\n\n# A tibble: 2 × 3\n  x         y     z\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a         2     1\n2 b         3     4\n\n\n\n\n\n\n\n\n\n\n\nOperations on Matrix and Data Frame\n\n\n\n\n\n\n\nCode\nmydata[, 1]                     # extract the first column\n\n\n  a   b   c   d   e \n140 120 160 145 125 \n\n\nCode\nmydata[1, ]                     # extract the first row\n\n\nWeight.lbs  Height.in \n       140         65 \n\n\nCode\nmydata[1:2, ]                   # extract the first two rows\n\n\n  Weight.lbs Height.in\na        140        65\nb        120        60\n\n\nCode\nmydata[3, 2]                    # extract the element in the third row and the second column\n\n\n[1] 63\n\n\nCode\ndf[seq(1, 7, 2), ]              # extract every second row\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n3        160        63 Female\n5        125        61 Female\n7        165        68   Male\n\n\nCode\nseq(1, 7, 2)\n\n\n[1] 1 3 5 7\n\n\nCode\nsubset(df, Gender == \"Male\")    # select based on value\n\n\n  Weight.lbs Height.in Gender\n6        180        70   Male\n7        165        68   Male\n\n\nCode\nt(mydata)                       # transpose of matrix\n\n\n             a   b   c   d   e\nWeight.lbs 140 120 160 145 125\nHeight.in   65  60  63  66  61\n\n\nCode\nmydata[, 1] * mydata[, 2]       # element-wise multiplication\n\n\n    a     b     c     d     e \n 9100  7200 10080  9570  7625 \n\n\nCode\nmydata %*% t(mydata)            # matrix multiplication\n\n\n      a     b     c     d     e\na 23825 20700 26495 24590 21465\nb 20700 18000 22980 21360 18660\nc 26495 22980 29569 27358 23843\nd 24590 21360 27358 25381 22151\ne 21465 18660 23843 22151 19346\n\n\n\n\n\n\n\n\n\n\n\nPlotting with the ggplot2 Package\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\ndata(\"USArrests\")\ndat = USArrests %&gt;% as_tibble()\ndat %&gt;% \n  ggplot(aes(x=UrbanPop, y=Murder)) + \n  geom_point()\n\n\n\n\n\n\n\nCode\ndat_long = dat %&gt;%\n  tidyr::pivot_longer(1:4,names_to = \"Variable\", values_to = \"Value\") \nhead(dat_long)\n\n\n# A tibble: 6 × 2\n  Variable Value\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Murder    13.2\n2 Assault  236  \n3 UrbanPop  58  \n4 Rape      21.2\n5 Murder    10  \n6 Assault  263  \n\n\nCode\n# faceted histogram\nggplot(dat_long, aes(Value)) + \n  geom_histogram(bins=20, fill=\"grey80\", color=\"white\") + \n  facet_wrap(~Variable, scales=\"free\") + \n  labs(title = \"Distributions by Variable\")"
  },
  {
    "objectID": "ch1/01-intro.html#organization-of-data-and-notation",
    "href": "ch1/01-intro.html#organization-of-data-and-notation",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.4 Organization of Data and Notation",
    "text": "1.4 Organization of Data and Notation\n\nn = the number of observations or units\n\np = the number of variables measured on each unit\n\nIf p = 1, then we are back in the usual univariate setting\n\nx_{ik} = the i-th observation of the k-th variable\n\n\n\\text{Observations} \\quad \\overset{\\text{Variables}}{\n\\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\n}\n\n\nData matrix:  X_{n \\times p}=\\left[ \\begin{array}{cccc} x_{11} & x_{12} & \\cdots & x_{1p} \\\\ x_{21} & x_{22} & \\cdots & x_{2p} \\\\ \\vdots & \\vdots & & \\vdots  \\\\ x_{n1} & x_{n2} & \\cdots & x_{np}\\end{array} \\right ] \nThis can be written as n rows or as p columns \nX_{n \\times p} =\n\\begin{bmatrix}\n\\mathbf{x}_1^{\\prime} \\\\\n\\mathbf{x}_2^{\\prime} \\\\\n\\vdots \\\\\n\\mathbf{x}_n^{\\prime}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{x}_1^{\\top} \\\\\n\\mathbf{x}_2^{\\top} \\\\\n\\vdots \\\\\n\\mathbf{x}_n^{\\top}\n\\end{bmatrix}\n=\n\\left[ \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_p \\right]\n where both \\prime and \\top represent matrix transpose.\n\n\n\nR Code: Data Organization\nX = as.matrix(USArrests)\ndim(X)\n\n\n[1] 50  4\n\n\n\n\nR Code: Matrix Transpose\nt(X[1:5,])\n\n\n         Alabama Alaska Arizona Arkansas California\nMurder      13.2   10.0     8.1      8.8        9.0\nAssault    236.0  263.0   294.0    190.0      276.0\nUrbanPop    58.0   48.0    80.0     50.0       91.0\nRape        21.2   44.5    31.0     19.5       40.6"
  },
  {
    "objectID": "ch1/01-intro.html#descriptive-statistics",
    "href": "ch1/01-intro.html#descriptive-statistics",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.5 Descriptive Statistics",
    "text": "1.5 Descriptive Statistics\n\n1.5.1 Sample Mean\n\nThe sample mean of the kth variable (k = 1,...,p) is \n\\bar{x}_k = \\frac{1}{n} \\sum_{i = 1}^n x_{ik}\n\n\n\n\n1.5.2 Sample Variance and Sample Standard Deviation\n\nThe sample variance of the kth variable is \ns^2_k = \\frac{1}{n-1} \\sum_{i=1}^n (x_{ik} - \\bar{x}_k)^2  \n\nThe sample standard deviation is given by \ns_k = \\sqrt{s^2_k}\n\nWe often use s_{kk} to denote the sample variance for the k-th variable. Thus, \ns^2_k = s_{kk}\n\n\n\n\n1.5.3 Sample Covariance and Sample Correlation\n\nThe sample covariance between variable k and variable j is computed as \ns_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (x_{ij} - \\bar{x}_j) (x_{ik} - \\bar{x}_k)\n\nIf variables k and j are independent, the population covariance will be exactly zero, but the sample covariance will vary about zero.\nThe sample correlation between variables k and j is defined as \nr_{jk} = \\frac{s_{jk}}{\\sqrt{s_{jj}} \\sqrt{s_{kk}}}\n\nr_{jk} is between -1 and 1.\nr_{jk} = r_{kj}\nThe sample correlation is equal to the sample covariance if measurements are standardized.\nThe sample correlation (r_{ij}) will vary about the value of the population correlation (\\rho_{ij})\n\n\n\n\n\n\n\nR Code: Descriptive Statistics\n\n\n\n\n\n\n# load built-in US crime rates data\ndata(\"USArrests\") \ndat = USArrests \nhead(dat)\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\n\n\nSample mean\nmu = colMeans(dat)\nmu \n\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\n\nSample mean\nlibrary(dplyr)\ndat %&gt;% \n  summarise(across(where(is.numeric), mean))\n\n\n  Murder Assault UrbanPop   Rape\n1  7.788  170.76    65.54 21.232\n\n\n\n\nSample variance\ns2 = apply(dat, 2, var)\ns2 \n\n\n    Murder    Assault   UrbanPop       Rape \n  18.97047 6945.16571  209.51878   87.72916 \n\n\nSample variance\n# using dplyr\ndat %&gt;% \n  summarise(across(where(is.numeric), var))\n\n\n    Murder  Assault UrbanPop     Rape\n1 18.97047 6945.166 209.5188 87.72916\n\n\n\n\nSample standard deviation\n# compute standard deviation from data \ns = apply(dat, 2, sd)  \n# or from sample variance \ns = sqrt(s2)\ns \n\n\n   Murder   Assault  UrbanPop      Rape \n 4.355510 83.337661 14.474763  9.366385 \n\n\n\n\nSample covariance\nn = nrow(dat)\ns_jk = 1/(n-1) * sum((dat[,1] - mu[1]) * (dat[,2] - mu[2]))\ns_jk \n\n\n[1] 291.0624\n\n\n\n\nSample correlation\nr_jk = s_jk / sqrt(s2[1] * s2[2])\n\n\n\n\n\n\n\n1.5.4 Covariance and Correlation Measures\n\nCovariance and correlation measure linear association.\nOther non-linear (or curved) relationships may exist among variables even if r_{jk} = 0.\nA population correlation of zero means no linear association,\nbut it does not necessarily imply independence.\n\n\n\n\n\n\nCorrelation Measures Linear Association\n\n\n\n\n\n\n\n\n\nNonlinear Dependence with (Near) Zero Correlation"
  },
  {
    "objectID": "ch1/01-intro.html#matrix-organization-of-descriptive-statistics",
    "href": "ch1/01-intro.html#matrix-organization-of-descriptive-statistics",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.6 Matrix Organization of Descriptive Statistics",
    "text": "1.6 Matrix Organization of Descriptive Statistics\n\n1.6.1 Sample Mean\n\nSample mean: \\bar{\\mathbf{x}} is the p \\times 1 vector of sample means:\n\n\n\\bar{\\mathbf{x}} =\n\\begin{bmatrix}\n\\bar{x}_1 \\\\\n\\bar{x}_2 \\\\\n\\vdots \\\\\n\\bar{x}_p\n\\end{bmatrix}\n\n\n\\bar{\\mathbf{x}} is an estimate of the vector of population means:\n\n\n\\boldsymbol{\\mu} =\n\\begin{bmatrix}\n\\mu_1 \\\\\n\\mu_2 \\\\\n\\vdots \\\\\n\\mu_p\n\\end{bmatrix}\n\n\n\nR Code: Sample Mean\nX = as.matrix(USArrests)\nxbar = colMeans(X)\nxbar \n\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\n\n\nCentered Data: X_c = X - \\mathbf{1}_n \\bar{\\mathbf{x}}^\\top\n\n\n\nR Code: Centered Data\nn = nrow(X) \nones_n = matrix(1, n, ncol=1)\nXc = X - ones_n %*% t(xbar)\n\n\n\n\n1.6.2 Sample Covariance\n\nS is the p \\times p symmetric matrix of sample variances (on the diagonal) and sample covariances (the off-diagonal elements):\n\n\nS =\n\\begin{bmatrix}\ns_{11} & s_{12} & s_{13} & \\cdots & s_{1p} \\\\\ns_{21} & s_{22} & s_{23} & \\cdots & s_{2p} \\\\\n\\vdots & \\vdots & \\vdots &        & \\vdots \\\\\ns_{p1} & s_{p2} & s_{p3} & \\cdots & s_{pp}\n\\end{bmatrix}\n= \\frac{1}{n-1} \\sum_{i=1}^n (\\mathbf{x}_i - \\bar{\\mathbf{x}})(\\mathbf{x}_i - \\bar{\\mathbf{x}})^{\\top} = \\frac{1}{n-1} X_c^\\top X_c\n\n\nS is an estimate of the population covariance matrix:\n\n\n\\Sigma =\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\sigma_{13} & \\cdots & \\sigma_{1p} \\\\\n\\sigma_{21} & \\sigma_{22} & \\sigma_{23} & \\cdots & \\sigma_{2p} \\\\\n\\vdots      & \\vdots      & \\vdots      &        & \\vdots      \\\\\n\\sigma_{p1} & \\sigma_{p2} & \\sigma_{p3} & \\cdots & \\sigma_{pp}\n\\end{bmatrix}\n\n\n\nR Code: Sample Covariance\nS = cov(X) \n# or using matrix algebra\nS_mat = t(Xc)%*%Xc/(n-1)\nsignif(cbind(S, S_mat),4)\n\n\n          Murder Assault UrbanPop   Rape  Murder Assault UrbanPop   Rape\nMurder    18.970   291.1    4.386  22.99  18.970   291.1    4.386  22.99\nAssault  291.100  6945.0  312.300 519.30 291.100  6945.0  312.300 519.30\nUrbanPop   4.386   312.3  209.500  55.77   4.386   312.3  209.500  55.77\nRape      22.990   519.3   55.770  87.73  22.990   519.3   55.770  87.73\n\n\n\n\n1.6.3 Sample Correlation\n\nThe p \\times p matrix of sample correlations is also symmetric:\n\n\nR =\n\\begin{bmatrix}\n1       & r_{12} & r_{13} & \\cdots & r_{1p} \\\\\nr_{21}  & 1      & r_{23} & \\cdots & r_{2p} \\\\\n\\vdots  & \\vdots & \\vdots &        & \\vdots \\\\\nr_{p1}  & r_{p2} & r_{p3} & \\cdots & 1\n\\end{bmatrix}\n= D^{-1/2} \\, S \\, D^{-1/2}\n\n\nD^{-1/2} is a diagonal matrix with (j,j) entry 1/\\sqrt{s_{jj}} = 1/s_j, i.e.,\n\n\nD^{-1/2} =\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{s_{11}}} & 0                       & 0                       & \\cdots & 0 \\\\\n0                       & \\frac{1}{\\sqrt{s_{22}}} & 0                       & \\cdots & 0 \\\\\n\\vdots                  & \\vdots                  & \\vdots                  &        & \\vdots \\\\\n0                       & 0                       & 0                       & \\cdots & \\frac{1}{\\sqrt{s_{pp}}}\n\\end{bmatrix}\n\n\nR is an estimate of the population correlation matrix \nP =\n\\begin{bmatrix}\n1          & \\rho_{12} & \\rho_{13} & \\cdots & \\rho_{1p} \\\\\n\\rho_{21}  & 1         & \\rho_{23} & \\cdots & \\rho_{2p} \\\\\n\\vdots     & \\vdots    & \\vdots    &        & \\vdots   \\\\\n\\rho_{p1}  & \\rho_{p2} & \\rho_{p3} & \\cdots & 1\n\\end{bmatrix}\n\n\n\n\nR Code: Sample Correlation\nR = cor(X)\nR\n\n\n             Murder   Assault   UrbanPop      Rape\nMurder   1.00000000 0.8018733 0.06957262 0.5635788\nAssault  0.80187331 1.0000000 0.25887170 0.6652412\nUrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\nRape     0.56357883 0.6652412 0.41134124 1.0000000\n\n\n\n\nR Code: Pairwise Scatterplots and Correlations\nGGally::ggpairs(dat)"
  },
  {
    "objectID": "ch1/01-intro.html#standardization",
    "href": "ch1/01-intro.html#standardization",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.7 Standardization",
    "text": "1.7 Standardization\n\n1.7.1 Standardized Data (or z-Scores)\n\nSuppose x_{ij} is the measurement on the j-th outcome variable for the i-th subject in the data set.\nThe standardized value is\n\nz_{ij} = \\frac{x_{ij} - \\bar{x}_{j}}{s_j}\n\nThe entire set of p standardized responses for the i-th subject can be computed as\n\n\\mathbf{z}_i =\n\\begin{bmatrix}\nz_{i1} \\\\\nz_{i2} \\\\\n\\vdots \\\\\nz_{ip}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\dfrac{x_{i1} - \\bar{x}_{1}}{s_1} \\\\\n\\dfrac{x_{i2} - \\bar{x}_{2}}{s_2} \\\\\n\\vdots \\\\\n\\dfrac{x_{ip} - \\bar{x}_{p}}{s_p}\n\\end{bmatrix}\n= D^{-1/2} (\\mathbf{x}_i - \\bar{\\mathbf{x}})\n\n\n\n\nR Code: Standardized Data\ns_j = sqrt(diag(S))\n\nDsqrt = diag(1/s_j)\n\n# using matrix algebra\nZ =  (X -  matrix(1, nrow(X), 1) %*% matrix(xbar, 1)) %*% Dsqrt\n\n# using scale function \nX_scaled = as.matrix(scale(X, center=TRUE, scale=TRUE))\n\n\n# using mutate function\ndat_scaled &lt;- dat %&gt;%\n  mutate(across(everything(), ~ (.x - mean(.x)) / sd(.x)))\n\n\n\n\nR Code: Plotting the Data\np1 = ggplot(dat, aes(Murder, Assault)) + \n  geom_point(alpha=0.8) + \n  labs(title=\"Unscaled\")\n\np2 = ggplot(dat_scaled, aes(Murder, Assault)) + \n  geom_point(alpha=.8) + \n  labs(title=\"Standardized (z-scores)\")\n\npatchwork::wrap_plots(p1, p2, ncol=1)\n\n\n\n\n\n\n\n1.7.2 Standardized Population Mean\n\nThe vector of true means for a set of standardized responses is\na vector of zeros:\n\n\nE(\\mathbf{z}_i) =\nE\\begin{bmatrix}\nz_{i1} \\\\\nz_{i2} \\\\\n\\vdots \\\\\nz_{ip}\n\\end{bmatrix}\n=\nE\\begin{bmatrix}\n\\dfrac{x_{i1} - \\bar{x}_{1}}{s_1} \\\\\n\\dfrac{x_{i2} - \\bar{x}_{2}}{s_2} \\\\\n\\vdots \\\\\n\\dfrac{x_{ip} - \\bar{x}_{p}}{s_p}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{bmatrix}\n\n\nThe vector of estimated means for a set of standardized responses\nis also a vector of zeros.\n\n\n\n1.7.3 Standardized Population Covariance\n\nThe true covariance matrix for a set of standardized responses is the population correlation matrix:\n\n\n\\text{Var}(\\mathbf{z}_i) = P =\n\\begin{bmatrix}\n1 & \\rho_{12} & \\cdots & \\rho_{1p} \\\\\n\\rho_{21} & 1 & \\cdots & \\rho_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho_{p1} & \\rho_{p2} & \\cdots & 1\n\\end{bmatrix}\n\n\nAn estimate of the true covariance matrix for a set of standardized responses is the sample correlation matrix:\n\n\n\\widehat{\\text{Var}(\\mathbf{z}_i)} = R =\n\\begin{bmatrix}\n1 & r_{12} & \\cdots & r_{1p} \\\\\nr_{21} & 1 & \\cdots & r_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nr_{p1} & r_{p2} & \\cdots & 1\n\\end{bmatrix}\n= D^{-1/2} S D^{-1/2}"
  },
  {
    "objectID": "ch1/01-intro.html#exercises",
    "href": "ch1/01-intro.html#exercises",
    "title": "1  Introduction to Multivariate Data",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\n1.8.1 Exercise 1: Data Types\nCommon types of objects for data analysis are numeric, character, logical, factors, and dates. Character data do not have numerical values, such as names of people or words in a book, Logical data takes values of true or false and can be used to make decisions.\n\nFor each of the following commands, either explain why they should be errors, or explain the non-erroneous result.\n\n    x &lt;- c(\"1\",\"2\",\"3\")\n    max(x)\n    sort(x)\n    sum(x)\n\nFor the next two commands, either explain their results, or why they should produce errors.\n\n    y &lt;- c(\"1\",3,4)\n    y[2] + y[3]\n\nFor the next two commands, either explain their results, or why they should produce errors.\n\n    z &lt;- data.frame(z1=\"1\", z2=3, z3=5)\n    z[1,2] + z[1,3]\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\nx is bound to a vector of characters instead of numerical values. The functions max, sort, sum should take numerical values as input, so the values in x are first converted from characters to numerical values implicitly and then the functions apply to these incorrect numerical values\ny is a vector of characters, which cannot be used for addition\nz is a data frame, but the variable z1 is a character while z2 and z3 are numerical. Adding z2 and z3 will produce the correct results.\n\n\n\n\n\n\n1.8.2 Exercise 2: Working with Matrix and Data Frames\n\nA matrix is a 2D array, with rows and columns, much like you would have seen in linear algebra. Primarily we think of these as numeric objects. Arrays can have more than two dimensions. In multivariate analysis we are typically thinking of data in the form of a matrix, with samples/cases in the rows and variables represented as columns. Data frames are 2D arrays that could have multiple types of data in different columns. Lists are collections of possibly different length and different types of objects.\n\n\nCreate a matrix and print it out.\n\n\n\nView Solution\ndat = matrix(c(140, 120, 160, 145, 125, \n               65, 60, 63, 66, 61), \n             ncol = 2, byrow = FALSE) \n\n\n\n\nView Solution\ndat # or print(dat) \n\n\n     [,1] [,2]\n[1,]  140   65\n[2,]  120   60\n[3,]  160   63\n[4,]  145   66\n[5,]  125   61\n\n\n\nRename the column names of a matrix.\n\n\n\nView Solution\ncolnames(dat) = c(\"weight.lbs\", \"Height.in\")\ndat \n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        120        60\n[3,]        160        63\n[4,]        145        66\n[5,]        125        61\n\n\n\nData frames can store both columns of numeric data and columns of character data, columns of integers, and factors.\n\n\nCreate a data frame with Male and Female observations, and print out the data frame.\n\n\n\nView Solution\ndf = data.frame(\n  Weight.lbs = c(140, 120, 160, 145, 125,\n       180, 165), \n  Height.in = c(65, 60, 63, 66, 61, 70, 68),\n  Gender = c(rep(\"Female\", 5), rep(\"Male\", 2))\n  ) \n\ndf\n\n\n  Weight.lbs Height.in Gender\n1        140        65 Female\n2        120        60 Female\n3        160        63 Female\n4        145        66 Female\n5        125        61 Female\n6        180        70   Male\n7        165        68   Male\n\n\n\nGet the rows and columns of a data frame.\n\n\n\nView Solution\ndim(df)\n\n\n[1] 7 3\n\n\nView Solution\nnrow(df)\n\n\n[1] 7\n\n\nView Solution\nncol(df)\n\n\n[1] 3\n\n\n\nGet summary statistics of a data frame.\n\n\n\nView Solution\nsummary(df)\n\n\n   Weight.lbs      Height.in        Gender         \n Min.   :120.0   Min.   :60.00   Length:7          \n 1st Qu.:132.5   1st Qu.:62.00   Class :character  \n Median :145.0   Median :65.00   Mode  :character  \n Mean   :147.9   Mean   :64.71                     \n 3rd Qu.:162.5   3rd Qu.:67.00                     \n Max.   :180.0   Max.   :70.00                     \n\n\n\nOperations with Matrix and Data Frame\n\n\nExtract the first row and second column of a matrix.\n\n\n\nView Solution\ndat[1,]\n\n\nweight.lbs  Height.in \n       140         65 \n\n\nView Solution\ndat[,2]\n\n\n[1] 65 60 63 66 61\n\n\n\nSubset the first two rows of a matrix\n\n\n\nView Solution\ndat[1:2,]\n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        120        60\n\n\n\nSubset rows 1,3,5 of a matrix.\n\n\n\nView Solution\ndat[c(1,3,5), ]\n\n\n     weight.lbs Height.in\n[1,]        140        65\n[2,]        160        63\n[3,]        125        61\n\n\n\nSelect all the Male observations from a data frame.\n\n\n\nView Solution\nsubset(df, Gender==\"Male\")\n\n\n  Weight.lbs Height.in Gender\n6        180        70   Male\n7        165        68   Male\n\n\n\nTranspose of a matrix\n\n\n\nView Solution\nA = matrix(c(3,1,2,4), ncol=2)\nA\n\n\n     [,1] [,2]\n[1,]    3    2\n[2,]    1    4\n\n\n\nMatrix multiplication\n\n\n\nView Solution\nB = matrix(c(1,2,3,4), ncol=2)\nA %*% B \n\n\n     [,1] [,2]\n[1,]    7   17\n[2,]    9   19\n\n\nView Solution\nB %*% A \n\n\n     [,1] [,2]\n[1,]    6   14\n[2,]   10   20\n\n\n\nMatrix inversion\n\n\n\nView Solution\nsolve(A)\n\n\n     [,1] [,2]\n[1,]  0.4 -0.2\n[2,] -0.1  0.3\n\n\n\n\n1.8.3 Exercise 3: Linear Algebra\nConsider the linear system A X = b, where A is an n\\times n positive definite matrix and b is a n-dimensional vector, the unique solution is X = A^{-1}b. Please answer the following questions:\n\nWrite an R function called my_solver() such that given inputs A and b, the function my_solver() returns the solution of the linear system, i.e., X &lt;- my_solver(A, b).\nRun the following code to get A and b.\n\nset.seed(123)\nA = matrix(c(5,1,1,6), ncol=2)\nn = nrow(A)\nb = rnorm(n,1)\nThen use your function my_solver() to produce the answer and verify your solution. (hint: AX should be equal to b)\n\n\nView Solution\nmy_solver &lt;- function(A, b){\n  x = solve(A, b)\n  return(x)\n}\n\nA = matrix(c(5,1,1,6), ncol=2)\nn = nrow(A)\nb = rnorm(n,1)\nx1 = my_solver(A, b)\nsum((A%*%x1-b)^2)\n\n\n[1] 1.232595e-32\n\n\n\n\n1.8.4 Exercise 4: Working with ggplot2 Package\nEPA monitors Air Quality data across the entire U.S. The file AQSdata.csv contains daily PM 2.5 concentrations and other information. Please answer the following questions using the ggplot() function for plotting. In addition make sure that all the x-axis and y-axis labels have 14 font size.\n\nRead the data file AQSdata.csv into R.\nGenerate density plots of PM2.5 concentrations grouped by County in one single panel, where each density should have its own color. What do you find from the figure?\nPlot histograms of PM2.5 concentrations across different counties with one panel for one histogram.\nGenerate boxplots of PM2.5 concentrations by County. What would you say about the distributions?\nReorder the boxplots above by the median value of PM2.5 concentrations.\nConverting the Site ID to a factor and plot the histogram grouped by Site ID.\nGenerate the time series plot for the monitoring Site ID 450190048.\nPlot time series of PM2.5 concentrations for all monitoring sites in one panel, where each site has its own color\nPlot time series of PM2.5 concentrations across all monitoring sites in multiple panels, where one panel only has one site, and each row only has two panels.\nIn the time series plot, there seems to be not enough space to hold the x-axis labels. One way to avoid this is to rotate the axis labels. Please rotate all the time labels 45 degree.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(readr)\nlibrary(lubridate)\n\ndf = read_csv(\"AQSdata.csv\")\nhead(df)\n\n\n# A tibble: 6 × 20\n  Date       Source `Site ID`   POC Daily Mean PM2.5 Con…¹ UNITS DAILY_AQI_VALUE\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;                  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n1 11/09/2021 AQS    450190020     1                   15.5 ug/m…              58\n2 11/10/2021 AQS    450190020     1                   13.6 ug/m…              54\n3 11/11/2021 AQS    450190020     1                    8.1 ug/m…              34\n4 11/12/2021 AQS    450190020     1                    7.1 ug/m…              30\n5 11/13/2021 AQS    450190020     1                   10.7 ug/m…              45\n6 11/14/2021 AQS    450190020     1                    7.5 ug/m…              31\n# ℹ abbreviated name: ¹​`Daily Mean PM2.5 Concentration`\n# ℹ 13 more variables: `Site Name` &lt;chr&gt;, DAILY_OBS_COUNT &lt;dbl&gt;,\n#   PERCENT_COMPLETE &lt;dbl&gt;, AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;,\n#   CBSA_CODE &lt;dbl&gt;, CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;,\n#   COUNTY_CODE &lt;chr&gt;, COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;\n\n\nCode\ntheme_mat = theme(axis.text = element_text(size = 14),\n                  axis.title = element_text(size = 14, face = \"bold\"))\ndf = rename(df, PM2.5 = `Daily Mean PM2.5 Concentration`)\nggplot(df) +\n  geom_freqpoly(aes(\n    x = PM2.5,\n    y = after_stat(density),\n    color = COUNTY\n  ), binwidth = 2) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = PM2.5), binwidth = .8) +\n  facet_wrap(~ COUNTY, ncol = 3) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\nCode\nggplot(df) +\n  geom_boxplot(aes(x = COUNTY, y = PM2.5)) +\n  xlab(\"County\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\nCode\nggplot(df) +\n  geom_boxplot(aes(x = reorder(COUNTY, PM2.5, FUN = median), \n                   y = PM2.5)) +\n  xlab(\"County\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\nCode\ndf1 = df\ndf1$`Site ID` =  as.factor(df$`Site ID`)\nggplot(df1) +\n  geom_freqpoly(aes(x = PM2.5, color = `Site ID`), binwidth = 2) +\n  xlab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat\n\n\n\n\n\nCode\ndf1 %&gt;%\n  filter(`Site ID` == 450190048) %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5)) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\n\n\n\n\n\nCode\ndf1 %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5, color = `Site ID`)) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\n\n\n\n\n\nCode\ng &lt;- df1 %&gt;%\n  ggplot() +\n  geom_line(aes(x = mdy(Date), y = PM2.5)) +\n  facet_wrap(~ `Site ID`, ncol = 2) +\n  labs(x = \"Time\", y = \"Daily PM2.5 concentration (ug/m3 LC)\") + \n  theme_mat\nprint(g)\n\n\n\n\n\nCode\ng + theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\n\n\n\n\n\n1.8.5 Exercise 5: Working with dplyr Package\nContinuing working with the above PM 2.5 data.\n\nFilter all the observations in the county Greenville. How many observations are there?\nFilter all the observations in Greenville in August 2021\nFilter all the observations in Greenville in August 2021 and select the variables PM2.5 concentrations, Date, latitude and longitude of sites\nGenerate scatterplots of PM2.5 against latitude and longitude in two different panels\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\n\ndf %&gt;%\n  filter(COUNTY == \"Greenville\")\n\n\n# A tibble: 937 × 20\n   Date       Source `Site ID`   POC PM2.5 UNITS    DAILY_AQI_VALUE `Site Name` \n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       \n 1 01/01/2021 AQS    450450015     1   6.3 ug/m3 LC              26 Greenville …\n 2 01/02/2021 AQS    450450015     1   6.6 ug/m3 LC              28 Greenville …\n 3 01/03/2021 AQS    450450015     1   5.4 ug/m3 LC              23 Greenville …\n 4 01/05/2021 AQS    450450015     1   7.4 ug/m3 LC              31 Greenville …\n 5 01/06/2021 AQS    450450015     1   7.7 ug/m3 LC              32 Greenville …\n 6 01/07/2021 AQS    450450015     1   9.5 ug/m3 LC              40 Greenville …\n 7 01/08/2021 AQS    450450015     1   7.5 ug/m3 LC              31 Greenville …\n 8 01/09/2021 AQS    450450015     1   5.3 ug/m3 LC              22 Greenville …\n 9 01/10/2021 AQS    450450015     1  12.1 ug/m3 LC              51 Greenville …\n10 01/11/2021 AQS    450450015     1  16.7 ug/m3 LC              61 Greenville …\n# ℹ 927 more rows\n# ℹ 12 more variables: DAILY_OBS_COUNT &lt;dbl&gt;, PERCENT_COMPLETE &lt;dbl&gt;,\n#   AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;, CBSA_CODE &lt;dbl&gt;,\n#   CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;, COUNTY_CODE &lt;chr&gt;,\n#   COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;\n\n\nCode\ndf %&gt;%\n  mutate(Date = mdy(Date), YM = format_ISO8601(Date, precision = \"ym\")) %&gt;%\n  filter(COUNTY == \"Greenville\", YM == \"2021-08\")\n\n\n# A tibble: 82 × 21\n   Date       Source `Site ID`   POC PM2.5 UNITS    DAILY_AQI_VALUE `Site Name` \n   &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       \n 1 2021-08-01 AQS    450450015     1  13.8 ug/m3 LC              55 Greenville …\n 2 2021-08-02 AQS    450450015     1  19   ug/m3 LC              66 Greenville …\n 3 2021-08-03 AQS    450450015     1  16.9 ug/m3 LC              61 Greenville …\n 4 2021-08-04 AQS    450450015     1  15.6 ug/m3 LC              58 Greenville …\n 5 2021-08-05 AQS    450450015     1  11   ug/m3 LC              46 Greenville …\n 6 2021-08-06 AQS    450450015     1  10.3 ug/m3 LC              43 Greenville …\n 7 2021-08-07 AQS    450450015     1   9.7 ug/m3 LC              40 Greenville …\n 8 2021-08-08 AQS    450450015     1  10   ug/m3 LC              42 Greenville …\n 9 2021-08-09 AQS    450450015     1  12   ug/m3 LC              50 Greenville …\n10 2021-08-10 AQS    450450015     1  12.5 ug/m3 LC              52 Greenville …\n# ℹ 72 more rows\n# ℹ 13 more variables: DAILY_OBS_COUNT &lt;dbl&gt;, PERCENT_COMPLETE &lt;dbl&gt;,\n#   AQS_PARAMETER_CODE &lt;dbl&gt;, AQS_PARAMETER_DESC &lt;chr&gt;, CBSA_CODE &lt;dbl&gt;,\n#   CBSA_NAME &lt;chr&gt;, STATE_CODE &lt;dbl&gt;, STATE &lt;chr&gt;, COUNTY_CODE &lt;chr&gt;,\n#   COUNTY &lt;chr&gt;, SITE_LATITUDE &lt;dbl&gt;, SITE_LONGITUDE &lt;dbl&gt;, YM &lt;chr&gt;\n\n\nCode\ndf %&gt;%\n  mutate(Date = mdy(Date), YM = format_ISO8601(Date, precision = \"ym\")) %&gt;%\n  filter(COUNTY == \"Greenville\", YM == \"2021-08\") %&gt;%\n  dplyr::select(PM2.5, Date, SITE_LATITUDE, SITE_LONGITUDE)\n\n\n# A tibble: 82 × 4\n   PM2.5 Date       SITE_LATITUDE SITE_LONGITUDE\n   &lt;dbl&gt; &lt;date&gt;             &lt;dbl&gt;          &lt;dbl&gt;\n 1  13.8 2021-08-01          34.8          -82.4\n 2  19   2021-08-02          34.8          -82.4\n 3  16.9 2021-08-03          34.8          -82.4\n 4  15.6 2021-08-04          34.8          -82.4\n 5  11   2021-08-05          34.8          -82.4\n 6  10.3 2021-08-06          34.8          -82.4\n 7   9.7 2021-08-07          34.8          -82.4\n 8  10   2021-08-08          34.8          -82.4\n 9  12   2021-08-09          34.8          -82.4\n10  12.5 2021-08-10          34.8          -82.4\n# ℹ 72 more rows\n\n\nCode\ndf %&gt;%\n  dplyr::select(PM2.5, SITE_LATITUDE, SITE_LONGITUDE) %&gt;%\n  pivot_longer(\n    cols = c(\"SITE_LATITUDE\", \"SITE_LONGITUDE\"),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) %&gt;%\n  ggplot(aes(x = value, y = PM2.5)) +\n  geom_point() +\n  facet_wrap( ~ variable, scale = \"free\") +\n  xlab(\"\") +\n  ylab(\"Daily PM2.5 concentration (ug/m3 LC)\") +\n  theme_mat"
  },
  {
    "objectID": "ch2/02-graphs.html#introduction",
    "href": "ch2/02-graphs.html#introduction",
    "title": "2  Graphs and Data Visualization",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\n\nGraphs reveal information about the center, shape, and spread of distributions.\nThey can also show typical and extreme outcomes, associations, and differences between groups.\nDifferent data types require different graph types."
  },
  {
    "objectID": "ch2/02-graphs.html#categorical-data",
    "href": "ch2/02-graphs.html#categorical-data",
    "title": "2  Graphs and Data Visualization",
    "section": "2.2 Categorical Data",
    "text": "2.2 Categorical Data\nCategorical data types:\n\nNominal: no natural order (e.g., eye color, blood type).\nOrdinal: ordered, but spacing not meaningful (e.g., therapy response).\nInterval: ordered and evenly spaced (e.g., fruit count).\n\n\n2.2.1 Bar Chart Example\nBar chart is used for displaying categorical variables.\n\n\nR Code: Bart Chart\ncolors &lt;- c('Red', 'Pink', 'White')\ncounts &lt;- c(80, 60, 40)\nbar_df &lt;- data.frame(Color = colors, Count = counts)\nggplot(bar_df, aes(x = Color, y = Count)) +\n  geom_bar(stat = 'identity', fill = 'steelblue') +\n  theme_minimal() +\n  labs(title = 'Poinsettia Colors')\n\n\n\n\n\n\nQuestion: What does the bar plot tell you about the color distribution for this poinsettia variety?"
  },
  {
    "objectID": "ch2/02-graphs.html#quantitative-data",
    "href": "ch2/02-graphs.html#quantitative-data",
    "title": "2  Graphs and Data Visualization",
    "section": "2.3 Quantitative Data",
    "text": "2.3 Quantitative Data\n\nMeasured on a numeric scale: e.g., weights, heights, cholesterol levels.\nUse histograms, boxplots, dotplots, density plots.\n\n\n2.3.1 Histogram Example (Tip Amounts)\nHistograms classify values into bins of equal width\n\nHeights of bars represent relative frequencies\n\n\n\nR Code: Histogram\ndata(\"tips\", package=\"reshape2\")\nggplot(tips, aes(x = tip)) +\n  geom_histogram(binwidth = 1, fill = 'orange', color = 'black') +\n  theme_minimal() +\n  labs(title = 'Histogram of Tip Amounts', x = 'Tip ($)', y = 'Count')\n\n\n\n\n\n\nQuestion: What does this histogram tell you about tips at this restaurant?\n\n\n\n\n\n\n\nTip\n\n\n\n\nCenter\nShape\nSpread\n\n\n\n\n\n2.3.2 Try Different Bin Widths\n\n\nR Code: Histograms with Different Bin Widths\nbw_list &lt;- c(0.25, 0.5, 1.0)\nplots &lt;- lapply(bw_list, function(bw) {\n  ggplot(tips, aes(x = tip)) +\n    geom_histogram(binwidth = bw, fill = 'lightblue', color = 'black') +\n    ggtitle(paste('Bin Width =', bw)) +\n    theme_minimal()\n})\nlibrary(gridExtra)\ndo.call(grid.arrange, c(plots, ncol = 1))\n\n\n\n\n\n\n\n2.3.3 Boxplot\nBoxplot is graphical display of the five number data summary (minimum, Q1, median, Q3, maximum). It is good for comparing samples from different populations.\n\n\nR Code: Boxplot\nggplot(tips, aes(y = tip)) +\n  geom_boxplot(fill = 'lightgreen') +\n  theme_minimal() +\n  labs(title = 'Boxplot of Tip Amounts', y = 'Tip ($)')"
  },
  {
    "objectID": "ch2/02-graphs.html#one-quantitative-one-categorical",
    "href": "ch2/02-graphs.html#one-quantitative-one-categorical",
    "title": "2  Graphs and Data Visualization",
    "section": "2.4 One Quantitative & One Categorical",
    "text": "2.4 One Quantitative & One Categorical\nSide by side box plots and dot plots can be used to compare distributions of a quantitative response variable for different levels of a categorical variable.\n\n\nR Code: Boxplots with Grouping\nggplot(tips, aes(x = day, y = tip)) +\n  geom_boxplot(fill = 'skyblue') +\n  theme_minimal() +\n  labs(title = 'Tip Amount by Day of Week')"
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-variables",
    "href": "ch2/02-graphs.html#two-quantitative-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.5 Two Quantitative Variables",
    "text": "2.5 Two Quantitative Variables\nScatterplots convey information about associations between quantitative variables and also about unusual observations.\n\n\nR Code: Scatterplot\ntips$bill &lt;- tips$total_bill\nggplot(tips, aes(x = bill, y = tip)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE, col = 'red') +\n  theme_minimal() +\n  labs(title = 'Tip vs Bill Amount', x = 'Bill ($)', y = 'Tip ($)')\n\n\n\n\n\n\nHow is the tip related to the bill?\nWhich variable is the response? Which is the explanatory variable?\nWhat type of relationship would you expect?"
  },
  {
    "objectID": "ch2/02-graphs.html#practice-problems",
    "href": "ch2/02-graphs.html#practice-problems",
    "title": "2  Graphs and Data Visualization",
    "section": "2.6 Practice Problems",
    "text": "2.6 Practice Problems\n\n2.6.1 Exercise 1: Bar Chart from Survey\nCreate a bar chart for the following survey results:\n\n\n\nPet Type\nCount\n\n\n\n\nDog\n15\n\n\nCat\n10\n\n\nFish\n3\n\n\nBird\n2\n\n\n\nUse ggplot2 package to visualize the data and describe what the chart tells you about pet preferences.\n\n\nView Solution\nlibrary(ggplot2)\npet_df &lt;- data.frame(\n  Pet = c(\"Dog\", \"Cat\", \"Fish\", \"Bird\"),\n  Count = c(15, 10, 3, 2)\n)\nggplot(pet_df, aes(x = Pet, y = Count, fill = Pet)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Pet Types\", x = \"Pet Type\", y = \"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n2.6.2 Exercise 2: Simulated Histogram\nSimulate 300 observations from a normal distribution with mean 70 and standard deviation 10.\n\nPlot a histogram using binwidth = 5 and 10.\nOverlay a density curve using geom_density().\nDescribe the center, spread, and shape of the distribution.\n\n\n\nView Solution\nset.seed(4750)\nx &lt;- rnorm(300, mean = 70, sd = 10)\n# Histogram with binwidth 5\np1 &lt;- ggplot(data.frame(x), aes(x = x)) +\n  geom_histogram(\n    binwidth = 5,\n    fill = \"skyblue\",\n    color = \"white\",\n    alpha = 0.7\n  ) +\n  geom_density(aes(y = after_stat(count) * 5),\n               color = \"red\",\n               linewidth = 1.2) +\n  labs(title = \"Histogram (binwidth = 5) with Density\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\n# Histogram with binwidth 10\np2 &lt;- ggplot(data.frame(x), aes(x = x)) +\n  geom_histogram(\n    binwidth = 10,\n    fill = \"orange\",\n    color = \"white\",\n    alpha = 0.7\n  ) +\n  geom_density(aes(y =  after_stat(count) * 10),\n               color = \"red\",\n               linewidth = 1.2) +\n  labs(title = \"Histogram (binwidth = 10) with Density\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\nlibrary(patchwork)\np1 / p2\n\n\n\n\n\n\n\n2.6.3 Exercise 3: Boxplots by Group\nSimulate exam scores for two groups of students (Group A and Group B), each with 50 observations.\n\nGenerate scores from rnorm(50, mean=80, sd=5) for Group A and rnorm(50, mean=75, sd=7) for Group B.\nCreate a combined data.frame and make a boxplot comparing the two groups.\nInterpret differences in central tendency and variability.\n\n\n\nView Solution\nset.seed(4750)\ngroup_a &lt;- rnorm(50, mean = 80, sd = 5)\ngroup_b &lt;- rnorm(50, mean = 75, sd = 7)\n\nscores &lt;- data.frame(\n  Score = c(group_a, group_b),\n  Group = rep(c(\"A\", \"B\"), each = 50)\n)\n\nlibrary(ggplot2)\nggplot(scores, aes(x = Group, y = Score, fill = Group)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Exam Scores by Group\", y = \"Score\")\n\n\n\n\n\nInterpretation:\n\nCentral tendency: Group A has a higher median and mean score than Group B.\nVariability: Group B shows a wider spread (greater interquartile range and more outliers) compared to Group A, which aligns with the larger standard deviation used in its simulation.\n\n\n\n2.6.4 Exercise 4: Scatterplot with Regression\nSimulate a dataset of 100 observations where x ~ runif(100, 0, 100) and y = 0.5 * x + rnorm(100, 0, 5).\n\nCreate a scatterplot of y vs x.\nAdd a regression line.\nDescribe the relationship and interpret the slope.\n\n\n\nView Solution\nset.seed(4750)\nx &lt;- runif(100, 0, 100)\ny &lt;- 0.5 * x + rnorm(100, 0, 5)\ndata &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(title = \"Scatterplot of y vs x with Regression Line\",\n       x = \"x\",\n       y = \"y\") +\n  theme_minimal()\n\n\n\n\n\nInterpretation:\n\nThere is a strong positive linear relationship between x and y, as expected from the model.\nThe slope of the regression line is close to 0.5, indicating that, on average, each 1-unit increase in x results in a 0.5-unit increase in y.\nThe scatter around the regression line reflects the normal error term with standard deviation 5."
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-one-categorical",
    "href": "ch2/02-graphs.html#two-quantitative-one-categorical",
    "title": "2  Graphs and Data Visualization",
    "section": "2.7 Two Quantitative & One Categorical",
    "text": "2.7 Two Quantitative & One Categorical\n\nGrouping: a graph consisting of a single panel with multiple variables differentiated using different visual characteristics such as color, shape, and size.\nFaceting: a graph consisting of several separate panels, with one for each level of the faceted variable, or combination of two faceted variables.\n\n\n\nR Code: Grouping\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = 'lm', se = FALSE) +\n  labs(title = 'Tip vs Bill by Gender')\n\n\n\n\n\n\n\nR Code: Faceting\nggplot(tips, aes(x=bill, y=tip)) + \n  geom_point(alpha=0.6) + \n  geom_smooth(method = 'lm', se = FALSE) + \n  facet_wrap(~ sex, ncol=2) + \n  labs(title = 'Tip vs Bill by Gender')\n\n\n\n\n\n\nDoes the relationship differ for men and women?"
  },
  {
    "objectID": "ch2/02-graphs.html#two-quantitative-two-categorical-variables",
    "href": "ch2/02-graphs.html#two-quantitative-two-categorical-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.8 Two Quantitative & Two Categorical Variables",
    "text": "2.8 Two Quantitative & Two Categorical Variables\n\n\nR Code: Grouping + Faceting\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(smoker ~ .) +\n  labs(title = \"Tip vs Bill by Sex and Smoking Status\",\n       x = \"Bill ($)\", y = \"Tip ($)\")\n\n\n\n\n\n\n\nR Code: Faceting Only\nggplot(tips, aes(x = bill, y = tip, color = sex)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(smoker ~ sex) +\n  labs(title = \"Tip vs Bill by Sex and Smoking Status\",\n       x = \"Bill ($)\", y = \"Tip ($)\")"
  },
  {
    "objectID": "ch2/02-graphs.html#three-variables",
    "href": "ch2/02-graphs.html#three-variables",
    "title": "2  Graphs and Data Visualization",
    "section": "2.9 Three Variables",
    "text": "2.9 Three Variables\n\n2.9.1 3D Scatterplot\n\n\nCode\nlibrary(plotly)\ndata(mtcars)\n# Example with mtcars\nplot_ly(\n  data = mtcars,\n  x = ~mpg, y = ~hp, z = ~wt,\n  type = 'scatter3d',\n  mode = 'markers',\n  color = ~as.factor(cyl)\n)\n\n\n\n\n\n\n\n\n2.9.2 Bubble Chart\n\n\nCode\nggplot(mtcars, \n       aes(x=mpg, y=hp, size=wt)) + \n  geom_point(alpha=.5, \n             fill=\"red\", \n             color=\"black\",\n             shape=21) + \n  scale_size_continuous(range = c(1, 5))"
  },
  {
    "objectID": "ch2/02-graphs.html#scatterplot-matrix",
    "href": "ch2/02-graphs.html#scatterplot-matrix",
    "title": "2  Graphs and Data Visualization",
    "section": "2.10 Scatterplot Matrix",
    "text": "2.10 Scatterplot Matrix\nA scatterplot matrix (sometimes called a “pairs plot”) is used to visualize the pairwise relationships between several quantitative variables in a dataset, all at once.\n\nEach row and column represents one variable.\nThe off-diagonal panels show scatterplots for each pair of variables (e.g., x vs y, x vs z, y vs z).\nThe diagonal often shows the distribution of each variable (as a histogram, density, or boxplot).\nYou can optionally color points by a group or class variable.\n\n\n\nR Code: Scatterplot Matrix\ndata(mtcars)\nlibrary(GGally)\nGGally::ggpairs(\n  mtcars,\n  columns = c(\"mpg\", \"hp\", \"wt\")\n)\n\n\n\n\n\n\n\nScatterplot Matrix with Base R\npairs(mtcars[,c(\"mpg\", \"hp\", \"wt\")])\n\n\n\n\n\n\n\nR Code: Sample Correlation\ncor(mtcars[,c(\"mpg\", \"hp\", \"wt\")])\n\n\n           mpg         hp         wt\nmpg  1.0000000 -0.7761684 -0.8676594\nhp  -0.7761684  1.0000000  0.6587479\nwt  -0.8676594  0.6587479  1.0000000"
  },
  {
    "objectID": "ch2/02-graphs.html#parallel-coordinates",
    "href": "ch2/02-graphs.html#parallel-coordinates",
    "title": "2  Graphs and Data Visualization",
    "section": "2.11 Parallel Coordinates",
    "text": "2.11 Parallel Coordinates\nA parallel coordinates plot is a powerful visualization tool used for exploring and comparing multivariate data (data with several quantitative variables). It’s especially valuable when you want to see how patterns, clusters, or outliers appear across many variables at once.\n\n\nR Code: Parallel Coordinates Plot\n# Convert cyl to factor for coloring\nmtcars$cyl &lt;- as.factor(mtcars$cyl)\n\nGGally::ggparcoord(\n  mtcars,\n  columns = c(1,4,6), # mpg, hp, wt\n  groupColumn = \"cyl\",\n  scale = \"uniminmax\",    # Normalize to [0,1] for fair comparison\n  showPoints = TRUE,\n  alphaLines = 0.6\n) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Cylinders\") +\n  labs(title = \"Parallel Coordinates Plot: mtcars (by cylinders)\")\n\n\n\n\n\nInterpretation:\n\nEach line is a car.\nThe color indicates the number of cylinders.\nCars with more cylinders generally have lower mpg and higher hp and weight."
  },
  {
    "objectID": "ch2/02-graphs.html#exercises",
    "href": "ch2/02-graphs.html#exercises",
    "title": "2  Graphs and Data Visualization",
    "section": "2.12 Exercises",
    "text": "2.12 Exercises\n\n2.12.1 Exercise 1: Ames Housing Data\nLoad the Ames Housing data into R and answer the following questions:\n\nAmes = read.csv(\"Ameshousing.csv\")\nhead(Ames)\n\n  SalePrice Bedrooms LotArea LivingArea GarageArea Neighborhood\n1    270000        4   11792       2283        632      Gilbert\n2    377500        3   14892       1746        758      Gilbert\n3    337500        3   12456       1718        786      NridgHt\n4    462000        4   14257       2772        754      NridgHt\n5    489900        2   14803       2084       1220      NridgHt\n6    555000        2   15431       2402        672      NridgHt\n\n\n\nSummary Statistics\n\n\nHow many homes were included in this study?\n\nWhat are the names of the variables for which information was collected?\nCompute the median living area, the mean living area and the standard error for the mean living area for all of the houses in the data set.\nCompute the median living area, the mean living area and the standard error for the mean living area for the houses in each neighborhood.\nCompute the number of houses, mean sale price and the standard error of the mean sale price for houses with living areas less than 1800 square feet.\nSummarize in a paragraph the information in the correlation matrix about associations between sales price, lot size, living area, garage area, and number of rooms from the sample correlation matrix.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\ndim(Ames)[1]\n\n\n[1] 168\n\n\n\n\nCode\nnames(Ames)\n\n\n[1] \"SalePrice\"    \"Bedrooms\"     \"LotArea\"      \"LivingArea\"   \"GarageArea\"  \n[6] \"Neighborhood\"\n\n\n\n\nCode\nmean_LivingArea &lt;- mean(Ames$LivingArea)\nmean_LivingArea\n\n\n[1] 1700.107\n\n\nCode\nmedian_LivingArea &lt;- median(Ames$LivingArea)\nsderr_LivingArea &lt;- sd(Ames$LivingArea)/ sqrt(length(Ames$LivingArea))\nsderr_LivingArea\n\n\n[1] 32.32775\n\n\n\n\nCode\nmean_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, mean)\nmean_LivingArea\n\n\n CollgCr  Gilbert  NridgHt \n1565.921 1658.966 1880.921 \n\n\nCode\nmedian_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, median)\nmedian_LivingArea\n\n\nCollgCr Gilbert NridgHt \n 1591.5  1560.0  1743.0 \n\n\nCode\nsd_LivingArea &lt;- tapply(Ames$LivingArea, Ames$Neighborhood, sd)\nsderr_LivingArea &lt;- sd_LivingArea / sqrt(tapply(Ames$LivingArea, Ames$Neighborhood, length))\nsderr_LivingArea\n\n\n CollgCr  Gilbert  NridgHt \n42.72812 56.21652 57.40376 \n\n\n\n\nCode\nAmes2 &lt;- Ames[ Ames$LivingArea&lt;1800, ]\nn &lt;- dim(Ames2)[1]\ncat(\"number of houses with living area &lt; 1800: \", n)\n\n\nnumber of houses with living area &lt; 1800:  116\n\n\n\n\nCode\nmean_Saleprice &lt;- mean(Ames2$SalePrice)\ncat(\"Mean Sale Price for Houses with Living Area &lt; 1800: \", mean_Saleprice)\n\n\nMean Sale Price for Houses with Living Area &lt; 1800:  215756.7\n\n\n\n\nCode\nsderr_SalePrice &lt;- sd(Ames2$SalePrice)/ sqrt(length(Ames2$SalePrice))\ncat(\"Stderror for Mean Sale Price: \", sderr_SalePrice)\n\n\nStderror for Mean Sale Price:  4693.031\n\n\n\n\n\n\nGraphical Summaries\n\n\nCreate a scatterplot with a smooth curve passed through the points.\nFit a least squares regression line to the data in the plot.\nWhat does the regression line indicate about sales prices of houses increase with living area?\nWhat information is provided by the plot with smooth curve?\nAdd a new variable to the data frame that contains information on sales price divided by the living area in the house, i.e., the sales price per square foot of living area.\nCreate a histogram for the price per square foot of living space.\nWhat does this histogram reveal about the distribution of costs per square foot of living space for houses sold in the Ames area? The description should be based on the shape, center and spread of the distribution.\nCreate separate plots of sales prices versus living space categorized for each neighborhood\nConstruct side-by-side box plots to compare prices per square foot of living space across neighborhoods.\nDescribe the relationship between sales price and total living area of house changes across the three neighborhoods.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n    geom_point(alpha=.7) + \n    geom_smooth() + \n    labs(\n      x=\"Living Area (sq ft)\",\n      y=\"Sale Price (dollars)\",\n      title=\"Sale Price vs Total Living Area\"\n    )\n\n\n\n\n\n\n\nCode\nlm(SalePrice ~ LivingArea, data = Ames)\n\n\n\nCall:\nlm(formula = SalePrice ~ LivingArea, data = Ames)\n\nCoefficients:\n(Intercept)   LivingArea  \n   -21769.1        159.5  \n\n\nCode\nplot( Ames$LivingArea, Ames$SalePrice, \n      xlab=\"Living Area (sq ft)\", \n      ylab=\"Sale Price (dollars)\",\n      main = \"Sale Price vs Total Living Area\")\nabline(lm(SalePrice~LivingArea, data=Ames), lty=1)\n\n\n\n\n\n\nThe slope of the regression suggests that the mean sale price of homes in the Ames area goes up by about 159.50 dollars for each additional square foot of living space.\nThe smooth curve indicates that there is an approximate straight line relationship between the mean home price and the living area of homes for homes with between 800 and 2000 square feet of living area, but the relationship curves up for larger home sizes. Also the variation in sale prices tends to increase with the amount of living area in the house.\n\n\n\nCode\nAmes$pricesqft  &lt;-  Ames$SalePrice/Ames$LivingArea \nhead(Ames)\n\n\n  SalePrice Bedrooms LotArea LivingArea GarageArea Neighborhood pricesqft\n1    270000        4   11792       2283        632      Gilbert  118.2654\n2    377500        3   14892       1746        758      Gilbert  216.2085\n3    337500        3   12456       1718        786      NridgHt  196.4494\n4    462000        4   14257       2772        754      NridgHt  166.6667\n5    489900        2   14803       2084       1220      NridgHt  235.0768\n6    555000        2   15431       2402        672      NridgHt  231.0575\n\n\n\n\nCode\nAmes %&gt;% ggplot() + \n  geom_histogram(aes(pricesqft), binwidth =20) \n\n\n\n\n\n\nThis histogram indicates that the distribution of costs per square foot of living space for houses sold in the Ames area is centered around $145 per square foot. The distribution is skewed to the right and it appears to be bimodal with one mode around $125 per square foot and another near $165 pre sqaure foot. Most houses cost between $100 and $200 per square foot of living space.\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n  geom_point() + \n  geom_smooth() + \n  facet_grid( . ~ Neighborhood) + \n  labs(\n    x=\"Living Area (sq ft)\",\n    y=\"Sale Price (dollars)\",\n    title=\"Sales Price vs Total Living Area\"\n  )\n\n\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=LivingArea, y=SalePrice)) + \n  geom_point() + \n  geom_smooth() + \n  facet_grid(Neighborhood ~ .) + \n  labs(\n    x=\"Living Area (sq ft)\",\n    y=\"Sale Price (dollars)\",\n    title=\"Sales Price vs Total Living Area\"\n  )\n\n\n\n\n\n\n\nCode\nAmes %&gt;% \n  ggplot(aes(x=Neighborhood, y=pricesqft)) + \n  geom_boxplot() + \n  labs(y=\"Sales Price per Square Foot\")\n\n\n\n\n\n\nIn all three neighborhoods sales prices tend to be larger for house with more living area. In the College Circle (CollgCr) and Northridge Heights (NridgHt) neighborhoods, there are strong linear relationships between these two variables. Because the slope is larger for houses in the Northridge Heights neighborhood, the price per square foot of living space is higher. There are more expensive houses in the Northridge Heights neighborhood. In Gilbert, the trend in sales prices is not so close to a straight line. There is little trend in sales prices for houses with less than 1,750 square feet of living space. There is also little trend in the sales prices for houses with living space above 1,900 square feet, but those houses are more expensive than house with less then 17,50 square feet. There is one relatively expensive house with about 1,750 square feet of living space that appears to be an outlier. Perhaps this house has an extremely large lot size or some additional buildings on the property. This should be investigated.\n\n\n\n\n\n\n2.12.2 Exercise 2: Music Clips Data\nThe music clips data is posted in music-plusnew-sub.csv. The data file has five quantitative variables containing audio information from 62 songs. The first two columns (Artist, Type) describe the artist and type of music. The raw data come from a time series for the sound produced by each music clip (track). For each time series the variance of amplitude, average amplitude, maximum amplitude, and two additional variables calculated from the spectral decomposition of the time series are calculated. The Type variable classifies the tracks as either Rock, Classical or New Wave, and there are 5 tracks that are not identified.\n\nRead the data into a data frame, indicating that the row names are in column 1 of the data file and that column is not a variable.\nObtain information on the dimensions of the data frame. Also list the column names. List the first six columns odf data.\nFirst select a subset of the data that contains only classical and rock music.\nFor classical and rock music make histograms for the avergae amplitude variable (LAve) faceted by Type. Set the binwidth to units of 10. How do the distributions of average amplitude values differ between classical and rock music?\nMake a scatterplot of LVar vs LAve, with points colored by the type of music. Describe differences between the patterns of the points on the plot corresponding to Rock and Classical music.\nSelect three music types. The other songs have missing values for the music type.\nMake a parallel coordinate plot\nReorder how the variables appear on the plot.\n\n\n\n\n\n\n\nView Solution\n\n\n\n\n\n\n\nCode\ndat = read.csv(\"music-plusnew-sub.csv\", row.names=1)  \n\nhead(dat) \n\n\n              Artist Type     LVar      LAve  LMax   LFEner     LFreq\nDancing Queen   Abba Rock 17600756 -90.00687 29921 105.9210  59.57379\nKnowing Me      Abba Rock  9543021 -75.76672 27626 102.8362  58.48031\nTake a Chance   Abba Rock  9049482 -98.06292 26372 102.3249 124.59397\nMamma Mia       Abba Rock  7557437 -90.47106 28898 101.6165  48.76513\nLay All You     Abba Rock  6282286 -88.95263 27940 100.3008  74.02039\nSuper Trouper   Abba Rock  4665867 -69.02084 25531 100.2485  81.40140\n\n\nCode\nstr(dat)\n\n\n'data.frame':   62 obs. of  7 variables:\n $ Artist: chr  \"Abba\" \"Abba\" \"Abba\" \"Abba\" ...\n $ Type  : chr  \"Rock\" \"Rock\" \"Rock\" \"Rock\" ...\n $ LVar  : num  17600756 9543021 9049482 7557437 6282286 ...\n $ LAve  : num  -90 -75.8 -98.1 -90.5 -89 ...\n $ LMax  : int  29921 27626 26372 28898 27940 25531 14699 8928 22962 15517 ...\n $ LFEner: num  106 103 102 102 100 ...\n $ LFreq : num  59.6 58.5 124.6 48.8 74 ...\n\n\nCode\nsummary(dat)\n\n\n    Artist              Type                LVar                LAve        \n Length:62          Length:62          Min.   :   293608   Min.   :-98.063  \n Class :character   Class :character   1st Qu.:  2844213   1st Qu.: -6.253  \n Mode  :character   Mode  :character   Median :  8210359   Median : -5.662  \n                                       Mean   : 19951792   Mean   : -7.807  \n                                       3rd Qu.: 24547475   3rd Qu.:  1.962  \n                                       Max.   :129472199   Max.   :216.232  \n      LMax           LFEner           LFreq       \n Min.   : 2985   Min.   : 83.88   Min.   : 41.41  \n 1st Qu.:16200   1st Qu.:101.69   1st Qu.: 99.18  \n Median :24431   Median :104.35   Median :175.29  \n Mean   :22486   Mean   :104.03   Mean   :231.39  \n 3rd Qu.:29918   3rd Qu.:108.15   3rd Qu.:315.12  \n Max.   :32766   Max.   :114.00   Max.   :877.77  \n\n\nCode\ntable(dat$Type)\n\n\n\nClassical  New wave      Rock \n       24         3        30 \n\n\nCode\ndf.sub = dat %&gt;% \n  dplyr::filter(Type==\"Rock\" | Type==\"Classical\")\n\nggplot(df.sub, aes(LAve)) + \n  geom_histogram(binwidth=10) + \n  facet_wrap( ~ Type, ncol=1)\n\n\n\n\n\nCode\nggplot(df.sub, aes(x=LVar, y=LAve, color=Type)) + \n  geom_point()\n\n\n\n\n\nCode\ndat2 = dat %&gt;% \n  filter(Type==\"Rock\" | Type==\"Classical\" | Type==\"New wave\")\nhead(dat2)\n\n\n              Artist Type     LVar      LAve  LMax   LFEner     LFreq\nDancing Queen   Abba Rock 17600756 -90.00687 29921 105.9210  59.57379\nKnowing Me      Abba Rock  9543021 -75.76672 27626 102.8362  58.48031\nTake a Chance   Abba Rock  9049482 -98.06292 26372 102.3249 124.59397\nMamma Mia       Abba Rock  7557437 -90.47106 28898 101.6165  48.76513\nLay All You     Abba Rock  6282286 -88.95263 27940 100.3008  74.02039\nSuper Trouper   Abba Rock  4665867 -69.02084 25531 100.2485  81.40140\n\n\nCode\nGGally::ggparcoord(dat2, columns=3:7,\n                   groupColumn = \"Type\",\n                   title=\"Parallel Coordinate Plot: Music Types\")\n\n\n\n\n\nCode\nGGally::ggparcoord(dat2, columns=c(4,3,5,6,7),\n                   groupColumn = \"Type\",\n                   title=\"Parallel Coordinate Plot: Music Types\")"
  }
]